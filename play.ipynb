{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a935e87e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "806e7995",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rendvvv/miniconda3/envs/lingu/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "\n",
    "import joblib\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "from pygments import lex\n",
    "from pygments.lexers import get_lexer_by_name, guess_lexer, find_lexer_class_by_name, get_all_lexers\n",
    "from pygments.util import ClassNotFound\n",
    "from pygments.token import Token\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from magika import Magika\n",
    "\n",
    "\n",
    "def batchify_list(data_list, batch_size):\n",
    "    \"\"\"Yield successive n-sized chunks from data_list.\"\"\"\n",
    "    for i in range(0, len(data_list), batch_size):\n",
    "        yield data_list[i:i + batch_size]\n",
    "\n",
    "def flatten_list(list_of_lists):\n",
    "    return [item for sublist in list_of_lists for item in sublist]\n",
    "\n",
    "def list_supported_languages():\n",
    "    # get_all_lexers() returns an iterator of tuples: \n",
    "    # (Long Name, (Aliases), (File Patterns), (Mime Types))\n",
    "    lexers = list(get_all_lexers())\n",
    "    \n",
    "    # Sort them alphabetically by long name\n",
    "    lexers.sort(key=lambda x: x[0])\n",
    "\n",
    "    print(f\"{'Language Name':<30} | {'Aliases (Use these IDs)'}\")\n",
    "    print(\"-\" * 70)\n",
    "    \n",
    "    for name, aliases, _, _ in lexers:\n",
    "        # Join aliases with commas for display\n",
    "        alias_str = \", \".join(aliases)\n",
    "        print(f\"{name:<30} | {alias_str}\")\n",
    "\n",
    "# list_supported_languages()\n",
    "\n",
    "def tokenize_code(code_string, language=None):\n",
    "    lexer = None\n",
    "    detected_lang = \"Unknown\"\n",
    "\n",
    "    # --- STRATEGY 1: Explicit Language (Hard Override) ---\n",
    "    if language:\n",
    "        try:\n",
    "            lexer = get_lexer_by_name(language)\n",
    "            detected_lang = lexer.name\n",
    "        except ClassNotFound:\n",
    "            print(f\"Warning: Lexer for '{language}' not found. Falling back to detection.\")\n",
    "\n",
    "    # --- Tokenization ---\n",
    "    raw_tokens = lex(code_string, lexer)\n",
    "    structured_tokens = []\n",
    "    \n",
    "    for token_type, value in raw_tokens:\n",
    "        if not value: continue\n",
    "        \n",
    "        token_data = {\n",
    "            \"text\": value,\n",
    "            \"type\": str(token_type),\n",
    "            \"base_type\": str(token_type).split('.')[1] if '.' in str(token_type) else \"Text\"\n",
    "        }\n",
    "        structured_tokens.append(token_data)\n",
    "\n",
    "    return {\n",
    "        \"language\": detected_lang,\n",
    "        \"tokens\": structured_tokens\n",
    "    }\n",
    "\n",
    "semeval2pygment_ids = {\n",
    "    \"C++\": \"c++\",\n",
    "    \"Python\": \"python\",\n",
    "    \"Java\": \"java\",\n",
    "    \"Go\": \"go\",\n",
    "    \"PHP\": \"php\",\n",
    "    \"C#\": \"c#\",\n",
    "    \"C\": \"c\",\n",
    "    \"JS\": \"javascript\",\n",
    "}\n",
    "pygment2semeval_ids = {v: k for k, v in semeval2pygment_ids.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c428a0f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 4) (10000, 4) (1000, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code</th>\n",
       "      <th>generator</th>\n",
       "      <th>label</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>77846</th>\n",
       "      <td>python\\na,b,c = map(int, input().split())\\n\\nm...</td>\n",
       "      <td>meta-llama/Llama-3.1-8B-Instruct</td>\n",
       "      <td>1</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273247</th>\n",
       "      <td>import math\\nimport sys\\ninput = sys.stdin.rea...</td>\n",
       "      <td>human</td>\n",
       "      <td>0</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     code  \\\n",
       "77846   python\\na,b,c = map(int, input().split())\\n\\nm...   \n",
       "273247  import math\\nimport sys\\ninput = sys.stdin.rea...   \n",
       "\n",
       "                               generator  label language  \n",
       "77846   meta-llama/Llama-3.1-8B-Instruct      1   Python  \n",
       "273247                             human      0   Python  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data\n",
    "N_SAMPLE = 10_000\n",
    "\n",
    "D_tr = pd.read_parquet(\"./data/task_a_training_set_1.parquet\").sample(n=N_SAMPLE)\n",
    "D_ev = pd.read_parquet(\"./data/task_a_validation_set.parquet\").sample(n=N_SAMPLE)\n",
    "D_te = pd.read_parquet(\"./data/test.parquet\")\n",
    "\n",
    "print(D_tr.shape, D_ev.shape, D_te.shape)\n",
    "D_tr.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "578cfc06",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:10<00:00, 926.55it/s]\n",
      "100%|██████████| 10000/10000 [00:11<00:00, 850.83it/s]\n"
     ]
    }
   ],
   "source": [
    "# Tokenize codes\n",
    "D_tr[\"token_obj\"] = [tokenize_code(code, language=semeval2pygment_ids[lang]) for code, lang in tqdm(zip(D_tr[\"code\"], D_tr[\"language\"]), total=len(D_tr))]\n",
    "D_tr[\"tokens\"] = [obj[\"tokens\"] for obj in D_tr[\"token_obj\"]]\n",
    "\n",
    "D_ev[\"token_obj\"] = [tokenize_code(code, language=semeval2pygment_ids[lang]) for code, lang in tqdm(zip(D_ev[\"code\"], D_ev[\"language\"]), total=len(D_ev))]\n",
    "D_ev[\"tokens\"] = [obj[\"tokens\"] for obj in D_ev[\"token_obj\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0e87c06d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prettify features\n",
    "D_tr[\"base\"] = [[token[\"base_type\"] for token in tokens] for tokens in D_tr[\"tokens\"]]\n",
    "D_ev[\"base\"] = [[token[\"base_type\"] for token in tokens] for tokens in D_ev[\"tokens\"]]\n",
    "\n",
    "D_tr[\"text\"] = [[token[\"text\"] for token in tokens] for tokens in D_tr[\"tokens\"]]\n",
    "D_ev[\"text\"] = [[token[\"text\"] for token in tokens] for tokens in D_ev[\"tokens\"]]\n",
    "\n",
    "D_tr[\"text_base\"] = [[(token[\"text\"], token[\"base_type\"]) for token in tokens] for tokens in D_tr[\"tokens\"]]\n",
    "D_ev[\"text_base\"] = [[(token[\"text\"], token[\"base_type\"]) for token in tokens] for tokens in D_ev[\"tokens\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e2444beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate language predictor\n",
    "from plid import PlidWithMagika\n",
    "\n",
    "lang_predictor = PlidWithMagika()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f9939f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate language predictor\n",
    "# D_ev[\"language_pred\"] = [lang_predictor.identify(t, n_segments=3, overlap_ratio=0.5) for t in tqdm(D_ev[\"code\"])]\n",
    "# print(classification_report(D_ev[\"language\"], D_ev[\"language_pred\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c2dde7c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define vocabularies\n",
    "VOCAB_TEXT = list(set(flatten_list(D_tr[\"text\"].to_list())))\n",
    "VOCAB_BASE = list(set(flatten_list(D_tr[\"base\"].to_list())))\n",
    "VOCAB_TEXT_BASE = list(set(flatten_list(D_tr[\"text_base\"].to_list())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "05bbad30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Literal',\n",
       " 'Name',\n",
       " 'Text',\n",
       " 'Keyword',\n",
       " 'Comment',\n",
       " 'Operator',\n",
       " 'Error',\n",
       " 'Punctuation']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VOCAB_BASE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2609f18f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data to human and machine\n",
    "D_human_tr = D_tr[D_tr[\"generator\"] == \"human\"]\n",
    "D_human_ev = D_ev[D_ev[\"generator\"] == \"human\"]\n",
    "\n",
    "D_machine_tr = D_tr[D_tr[\"generator\"] != \"human\"]\n",
    "D_machine_ev = D_ev[D_ev[\"generator\"] != \"human\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ab6fad33",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_FEATURE_LIST = [\"Text\", \"Comment\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "97b405a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "text_embedder = SentenceTransformer(\"google/embeddinggemma-300m\", device=\"mps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "54038ee6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4830/4830 [00:00<00:00, 38452.32it/s]\n",
      "100%|██████████| 5170/5170 [00:00<00:00, 71513.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2251 10608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Feature from comments\n",
    "comments_tr_human = flatten_list([[t for t, b in tbs if b == \"Comment\"] for tbs in tqdm(D_human_tr[\"text_base\"])])\n",
    "comments_tr_human = list(set(comments_tr_human))\n",
    "comments_tr_human = [x for x in comments_tr_human if x != \"\"]\n",
    "\n",
    "comments_tr_machine = flatten_list([[t for t, b in tbs if b == \"Comment\"] for tbs in tqdm(D_machine_tr[\"text_base\"])])\n",
    "comments_tr_machine = list(set(comments_tr_machine))\n",
    "comments_tr_machine = [x for x in comments_tr_machine if x != \"\"]\n",
    "\n",
    "print(len(comments_tr_human), len(comments_tr_machine))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f801a57",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 6/10 [00:27<00:18,  4.54s/it]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "MPS backend out of memory (MPS allocated: 5.18 GiB, other allocations: 12.95 GiB, max allowed: 18.13 GiB). Tried to allocate 13.59 MiB on private pool. Use PYTORCH_MPS_HIGH_WATERMARK_RATIO=0.0 to disable upper limit for memory allocations (may cause system failure).",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m embs = []\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m tqdm(batchify_list(comments_tr_human, \u001b[32m256\u001b[39m), total=\u001b[38;5;28mlen\u001b[39m(comments_tr_human) // \u001b[32m256\u001b[39m):\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m     embs.extend(\u001b[43mtext_embedder\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m.tolist())\n\u001b[32m      4\u001b[39m comments_tr_human_embs = np.array(embs)\n\u001b[32m      6\u001b[39m embs = []\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/lingu/lib/python3.12/site-packages/torch/utils/_contextlib.py:120\u001b[39m, in \u001b[36mcontext_decorator.<locals>.decorate_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    117\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecorate_context\u001b[39m(*args, **kwargs):\n\u001b[32m    119\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m--> \u001b[39m\u001b[32m120\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/lingu/lib/python3.12/site-packages/sentence_transformers/SentenceTransformer.py:1094\u001b[39m, in \u001b[36mSentenceTransformer.encode\u001b[39m\u001b[34m(self, sentences, prompt_name, prompt, batch_size, show_progress_bar, output_value, precision, convert_to_numpy, convert_to_tensor, device, normalize_embeddings, truncate_dim, pool, chunk_size, **kwargs)\u001b[39m\n\u001b[32m   1091\u001b[39m features.update(extra_features)\n\u001b[32m   1093\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m-> \u001b[39m\u001b[32m1094\u001b[39m     out_features = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1095\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.device.type == \u001b[33m\"\u001b[39m\u001b[33mhpu\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m   1096\u001b[39m         out_features = copy.deepcopy(out_features)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/lingu/lib/python3.12/site-packages/sentence_transformers/SentenceTransformer.py:1175\u001b[39m, in \u001b[36mSentenceTransformer.forward\u001b[39m\u001b[34m(self, input, **kwargs)\u001b[39m\n\u001b[32m   1169\u001b[39m             module_kwarg_keys = \u001b[38;5;28mself\u001b[39m.module_kwargs.get(module_name, [])\n\u001b[32m   1170\u001b[39m         module_kwargs = {\n\u001b[32m   1171\u001b[39m             key: value\n\u001b[32m   1172\u001b[39m             \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m kwargs.items()\n\u001b[32m   1173\u001b[39m             \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m module_kwarg_keys \u001b[38;5;129;01mor\u001b[39;00m (\u001b[38;5;28mhasattr\u001b[39m(module, \u001b[33m\"\u001b[39m\u001b[33mforward_kwargs\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m module.forward_kwargs)\n\u001b[32m   1174\u001b[39m         }\n\u001b[32m-> \u001b[39m\u001b[32m1175\u001b[39m     \u001b[38;5;28minput\u001b[39m = \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodule_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1176\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/lingu/lib/python3.12/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/lingu/lib/python3.12/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/lingu/lib/python3.12/site-packages/sentence_transformers/models/Transformer.py:261\u001b[39m, in \u001b[36mTransformer.forward\u001b[39m\u001b[34m(self, features, **kwargs)\u001b[39m\n\u001b[32m    238\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    239\u001b[39m \u001b[33;03mForward pass through the transformer model.\u001b[39;00m\n\u001b[32m    240\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    257\u001b[39m \u001b[33;03m        - 'all_layer_embeddings': If the model outputs hidden states, contains embeddings from all layers\u001b[39;00m\n\u001b[32m    258\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    259\u001b[39m trans_features = {key: value \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m features.items() \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.model_forward_params}\n\u001b[32m--> \u001b[39m\u001b[32m261\u001b[39m outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mauto_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mtrans_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    262\u001b[39m token_embeddings = outputs[\u001b[32m0\u001b[39m]\n\u001b[32m    263\u001b[39m features[\u001b[33m\"\u001b[39m\u001b[33mtoken_embeddings\u001b[39m\u001b[33m\"\u001b[39m] = token_embeddings\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/lingu/lib/python3.12/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/lingu/lib/python3.12/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/lingu/lib/python3.12/site-packages/transformers/utils/generic.py:1064\u001b[39m, in \u001b[36mcheck_model_inputs.<locals>.wrapper\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1061\u001b[39m                 monkey_patched_layers.append((module, original_forward))\n\u001b[32m   1063\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1064\u001b[39m     outputs = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1065\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m original_exception:\n\u001b[32m   1066\u001b[39m     \u001b[38;5;66;03m# If we get a TypeError, it's possible that the model is not receiving the recordable kwargs correctly.\u001b[39;00m\n\u001b[32m   1067\u001b[39m     \u001b[38;5;66;03m# Get a TypeError even after removing the recordable kwargs -> re-raise the original exception\u001b[39;00m\n\u001b[32m   1068\u001b[39m     \u001b[38;5;66;03m# Otherwise -> we're probably missing `**kwargs` in the decorated function\u001b[39;00m\n\u001b[32m   1069\u001b[39m     kwargs_without_recordable = {k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m kwargs.items() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m recordable_keys}\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/lingu/lib/python3.12/site-packages/transformers/models/gemma3/modeling_gemma3.py:570\u001b[39m, in \u001b[36mGemma3TextModel.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, cache_position, **kwargs)\u001b[39m\n\u001b[32m    567\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m output_hidden_states:\n\u001b[32m    568\u001b[39m     all_hidden_states += (hidden_states,)\n\u001b[32m--> \u001b[39m\u001b[32m570\u001b[39m layer_outputs = \u001b[43mdecoder_layer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    571\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    572\u001b[39m \u001b[43m    \u001b[49m\u001b[43mposition_embeddings_global\u001b[49m\u001b[43m=\u001b[49m\u001b[43mposition_embeddings_global\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    573\u001b[39m \u001b[43m    \u001b[49m\u001b[43mposition_embeddings_local\u001b[49m\u001b[43m=\u001b[49m\u001b[43mposition_embeddings_local\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    574\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcausal_mask_mapping\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdecoder_layer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mattention_type\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    575\u001b[39m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    576\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    577\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    578\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    579\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    580\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    581\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    583\u001b[39m hidden_states = layer_outputs[\u001b[32m0\u001b[39m]\n\u001b[32m    585\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m output_attentions:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/lingu/lib/python3.12/site-packages/transformers/modeling_layers.py:94\u001b[39m, in \u001b[36mGradientCheckpointingLayer.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     91\u001b[39m         logger.warning_once(message)\n\u001b[32m     93\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._gradient_checkpointing_func(partial(\u001b[38;5;28msuper\u001b[39m().\u001b[34m__call__\u001b[39m, **kwargs), *args)\n\u001b[32m---> \u001b[39m\u001b[32m94\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/lingu/lib/python3.12/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/lingu/lib/python3.12/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/lingu/lib/python3.12/site-packages/transformers/utils/deprecation.py:172\u001b[39m, in \u001b[36mdeprecate_kwarg.<locals>.wrapper.<locals>.wrapped_func\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    168\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m minimum_action \u001b[38;5;129;01min\u001b[39;00m (Action.NOTIFY, Action.NOTIFY_ALWAYS) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torchdynamo_compiling():\n\u001b[32m    169\u001b[39m     \u001b[38;5;66;03m# DeprecationWarning is ignored by default, so we use FutureWarning instead\u001b[39;00m\n\u001b[32m    170\u001b[39m     warnings.warn(message, \u001b[38;5;167;01mFutureWarning\u001b[39;00m, stacklevel=\u001b[32m2\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m172\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/lingu/lib/python3.12/site-packages/transformers/models/gemma3/modeling_gemma3.py:382\u001b[39m, in \u001b[36mGemma3DecoderLayer.forward\u001b[39m\u001b[34m(self, hidden_states, position_embeddings_global, position_embeddings_local, attention_mask, position_ids, past_key_values, output_attentions, use_cache, cache_position, **kwargs)\u001b[39m\n\u001b[32m    379\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    380\u001b[39m     position_embeddings = position_embeddings_global\n\u001b[32m--> \u001b[39m\u001b[32m382\u001b[39m hidden_states, self_attn_weights = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mself_attn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    383\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    384\u001b[39m \u001b[43m    \u001b[49m\u001b[43mposition_embeddings\u001b[49m\u001b[43m=\u001b[49m\u001b[43mposition_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    385\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    386\u001b[39m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    387\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    388\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    389\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    390\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    391\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    392\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    393\u001b[39m hidden_states = \u001b[38;5;28mself\u001b[39m.post_attention_layernorm(hidden_states)\n\u001b[32m    394\u001b[39m hidden_states = residual + hidden_states\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/lingu/lib/python3.12/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/lingu/lib/python3.12/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/lingu/lib/python3.12/site-packages/transformers/utils/deprecation.py:172\u001b[39m, in \u001b[36mdeprecate_kwarg.<locals>.wrapper.<locals>.wrapped_func\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    168\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m minimum_action \u001b[38;5;129;01min\u001b[39;00m (Action.NOTIFY, Action.NOTIFY_ALWAYS) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torchdynamo_compiling():\n\u001b[32m    169\u001b[39m     \u001b[38;5;66;03m# DeprecationWarning is ignored by default, so we use FutureWarning instead\u001b[39;00m\n\u001b[32m    170\u001b[39m     warnings.warn(message, \u001b[38;5;167;01mFutureWarning\u001b[39;00m, stacklevel=\u001b[32m2\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m172\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/lingu/lib/python3.12/site-packages/transformers/models/gemma3/modeling_gemma3.py:327\u001b[39m, in \u001b[36mGemma3Attention.forward\u001b[39m\u001b[34m(self, hidden_states, position_embeddings, attention_mask, past_key_values, cache_position, **kwargs)\u001b[39m\n\u001b[32m    324\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.config._attn_implementation != \u001b[33m\"\u001b[39m\u001b[33meager\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    325\u001b[39m     attention_interface = ALL_ATTENTION_FUNCTIONS[\u001b[38;5;28mself\u001b[39m.config._attn_implementation]\n\u001b[32m--> \u001b[39m\u001b[32m327\u001b[39m attn_output, attn_weights = \u001b[43mattention_interface\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    328\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    329\u001b[39m \u001b[43m    \u001b[49m\u001b[43mquery_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    330\u001b[39m \u001b[43m    \u001b[49m\u001b[43mkey_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    331\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalue_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    332\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    333\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdropout\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mattention_dropout\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[32;43m0.0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    334\u001b[39m \u001b[43m    \u001b[49m\u001b[43mscaling\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mscaling\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    335\u001b[39m \u001b[43m    \u001b[49m\u001b[43msliding_window\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msliding_window\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    336\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    337\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    339\u001b[39m attn_output = attn_output.reshape(*input_shape, -\u001b[32m1\u001b[39m).contiguous()\n\u001b[32m    340\u001b[39m attn_output = \u001b[38;5;28mself\u001b[39m.o_proj(attn_output)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/lingu/lib/python3.12/site-packages/transformers/integrations/sdpa_attention.py:106\u001b[39m, in \u001b[36msdpa_attention_forward\u001b[39m\u001b[34m(module, query, key, value, attention_mask, dropout, scaling, is_causal, **kwargs)\u001b[39m\n\u001b[32m     94\u001b[39m         attention_mask = torch.logical_not(attention_mask.bool()).to(query.device)\n\u001b[32m     96\u001b[39m attn_output = torch.nn.functional.scaled_dot_product_attention(\n\u001b[32m     97\u001b[39m     query,\n\u001b[32m     98\u001b[39m     key,\n\u001b[32m   (...)\u001b[39m\u001b[32m    104\u001b[39m     **sdpa_kwargs,\n\u001b[32m    105\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m106\u001b[39m attn_output = \u001b[43mattn_output\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtranspose\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcontiguous\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    108\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m attn_output, \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[31mRuntimeError\u001b[39m: MPS backend out of memory (MPS allocated: 5.18 GiB, other allocations: 12.95 GiB, max allowed: 18.13 GiB). Tried to allocate 13.59 MiB on private pool. Use PYTORCH_MPS_HIGH_WATERMARK_RATIO=0.0 to disable upper limit for memory allocations (may cause system failure)."
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 32\n",
    "\n",
    "embs = []\n",
    "for batch in tqdm(batchify_list(comments_tr_human, BATCH_SIZE), total=len(comments_tr_human) // BATCH_SIZE):\n",
    "    embs.extend(text_embedder.encode(batch).tolist())\n",
    "comments_tr_human_embs = np.array(embs)\n",
    "\n",
    "embs = []\n",
    "for batch in tqdm(batchify_list(comments_tr_machine, BATCH_SIZE), total=len(comments_tr_machine) // BATCH_SIZE):\n",
    "    embs.extend(text_embedder.encode(batch).tolist())\n",
    "comments_tr_machine_embs = np.array(embs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de8ca9b3",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (2321,2) (10628,2) ",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[52]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mseaborn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msns\u001b[39;00m\n\u001b[32m      5\u001b[39m pca = PCA(n_components=\u001b[32m2\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m pca.fit(\u001b[43mcomments_tr_human_embs\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[43mcomments_tr_machine_embs\u001b[49m)\n\u001b[32m      8\u001b[39m comments_tr_human_embs = pca.transform(comments_tr_human_embs)\n\u001b[32m      9\u001b[39m comments_tr_machine_embs = pca.transform(comments_tr_machine_embs)\n",
      "\u001b[31mValueError\u001b[39m: operands could not be broadcast together with shapes (2321,2) (10628,2) "
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "pca.fit(comments_tr_human_embs + comments_tr_machine_embs)\n",
    "\n",
    "comments_tr_human_embs_pcs = pca.transform(comments_tr_human_embs)\n",
    "comments_tr_machine_embs_pcs = pca.transform(comments_tr_machine_embs)\n",
    "\n",
    "plt.scatter(comments_tr_human_embs_pcs[:, 0], comments_tr_human_embs_pcs[:, 1])\n",
    "plt.scatter(comments_tr_machine_embs_pcs[:, 0], comments_tr_machine_embs_pcs[:, 1])\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "be63a37b",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (2321,2) (10628,2) ",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[53]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mcomments_tr_human_embs\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[43mcomments_tr_machine_embs\u001b[49m\n",
      "\u001b[31mValueError\u001b[39m: operands could not be broadcast together with shapes (2321,2) (10628,2) "
     ]
    }
   ],
   "source": [
    "comments_tr_human_embs + comments_tr_machine_embs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a7a90cfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5244/5244 [00:00<00:00, 69681.39it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['(',\n",
       " ',',\n",
       " ',',\n",
       " ')',\n",
       " ':',\n",
       " '[',\n",
       " '(',\n",
       " ',',\n",
       " ')',\n",
       " ',',\n",
       " '(',\n",
       " ',',\n",
       " ')',\n",
       " ',',\n",
       " '(',\n",
       " ',',\n",
       " ')',\n",
       " ']',\n",
       " '(',\n",
       " '(',\n",
       " ')',\n",
       " ')',\n",
       " '(',\n",
       " '(',\n",
       " ',',\n",
       " ',',\n",
       " ')',\n",
       " ')',\n",
       " '(',\n",
       " ',',\n",
       " ')',\n",
       " ':',\n",
       " ':',\n",
       " '(',\n",
       " '(',\n",
       " ',',\n",
       " ')',\n",
       " ')',\n",
       " ',',\n",
       " ':',\n",
       " ',',\n",
       " ',',\n",
       " '(',\n",
       " ',',\n",
       " ')',\n",
       " ':',\n",
       " '[',\n",
       " ']',\n",
       " '[',\n",
       " ']',\n",
       " '(',\n",
       " ',',\n",
       " ')',\n",
       " '(',\n",
       " ',',\n",
       " ')',\n",
       " '(',\n",
       " '(',\n",
       " ',',\n",
       " ')',\n",
       " ')',\n",
       " ':',\n",
       " '(',\n",
       " ',',\n",
       " '(',\n",
       " ',',\n",
       " ')',\n",
       " ')',\n",
       " '(',\n",
       " ')',\n",
       " ':',\n",
       " ':',\n",
       " ',',\n",
       " '(',\n",
       " ',',\n",
       " ')',\n",
       " '(',\n",
       " ')',\n",
       " '(',\n",
       " ')',\n",
       " ':',\n",
       " ':',\n",
       " '(',\n",
       " ')',\n",
       " '(',\n",
       " ')',\n",
       " '(',\n",
       " '(',\n",
       " ')',\n",
       " ')',\n",
       " '(',\n",
       " ')',\n",
       " ':',\n",
       " '(',\n",
       " ')',\n",
       " '(',\n",
       " ')',\n",
       " ':',\n",
       " ',',\n",
       " '[',\n",
       " ':',\n",
       " ']',\n",
       " '(',\n",
       " ')',\n",
       " ',',\n",
       " '(',\n",
       " ')',\n",
       " ',',\n",
       " '(',\n",
       " ')',\n",
       " '(',\n",
       " ')',\n",
       " '(',\n",
       " '(',\n",
       " ')',\n",
       " ')',\n",
       " ':',\n",
       " ':',\n",
       " '(',\n",
       " ')',\n",
       " ':',\n",
       " ':',\n",
       " '(',\n",
       " ')',\n",
       " '(',\n",
       " ')',\n",
       " '(',\n",
       " '(',\n",
       " ')',\n",
       " '(',\n",
       " ')',\n",
       " ')',\n",
       " '(',\n",
       " ')',\n",
       " ':',\n",
       " ',',\n",
       " '(',\n",
       " ',',\n",
       " '(',\n",
       " ')',\n",
       " '(',\n",
       " ')',\n",
       " ')',\n",
       " '{',\n",
       " '}',\n",
       " '(',\n",
       " ')',\n",
       " ':',\n",
       " ',',\n",
       " '(',\n",
       " ')',\n",
       " '(',\n",
       " ')',\n",
       " '[',\n",
       " ']',\n",
       " '[',\n",
       " ']',\n",
       " '(',\n",
       " ')',\n",
       " '(',\n",
       " ')',\n",
       " ':',\n",
       " '(',\n",
       " ',',\n",
       " '[',\n",
       " ']',\n",
       " ',',\n",
       " ')',\n",
       " '(',\n",
       " '(',\n",
       " ')',\n",
       " ')',\n",
       " ':',\n",
       " '(',\n",
       " ')',\n",
       " ',',\n",
       " ',',\n",
       " '(',\n",
       " ')',\n",
       " ':',\n",
       " ',',\n",
       " '(',\n",
       " ',',\n",
       " '(',\n",
       " ')',\n",
       " '(',\n",
       " ')',\n",
       " ')',\n",
       " '(',\n",
       " ')',\n",
       " ':',\n",
       " '(',\n",
       " ')',\n",
       " ':',\n",
       " ':',\n",
       " '(',\n",
       " ')',\n",
       " ':',\n",
       " '(',\n",
       " ')',\n",
       " '(',\n",
       " ')',\n",
       " ':',\n",
       " '(',\n",
       " ')',\n",
       " '(',\n",
       " ')',\n",
       " ':',\n",
       " '(',\n",
       " ')',\n",
       " '(',\n",
       " ',',\n",
       " ')',\n",
       " ':',\n",
       " '(',\n",
       " ')',\n",
       " '(',\n",
       " ')',\n",
       " ',',\n",
       " ',',\n",
       " '(',\n",
       " '(',\n",
       " ')',\n",
       " '(',\n",
       " ')',\n",
       " '(',\n",
       " ')',\n",
       " ')',\n",
       " '(',\n",
       " ')',\n",
       " '{',\n",
       " ';',\n",
       " ';',\n",
       " '(',\n",
       " ')',\n",
       " '{',\n",
       " ';',\n",
       " ';',\n",
       " '(',\n",
       " ')',\n",
       " ';',\n",
       " '(',\n",
       " ';',\n",
       " ';',\n",
       " ')',\n",
       " '{',\n",
       " '[',\n",
       " ']',\n",
       " ';',\n",
       " '}',\n",
       " '(',\n",
       " '.',\n",
       " '(',\n",
       " ')',\n",
       " ',',\n",
       " '.',\n",
       " '(',\n",
       " ')',\n",
       " ')',\n",
       " ';',\n",
       " '(',\n",
       " ';',\n",
       " ';',\n",
       " ')',\n",
       " '{',\n",
       " '[',\n",
       " ']',\n",
       " ';',\n",
       " '}',\n",
       " ';',\n",
       " '}',\n",
       " ';',\n",
       " '}',\n",
       " ',',\n",
       " ':',\n",
       " ':',\n",
       " '(',\n",
       " ',',\n",
       " ':',\n",
       " '[',\n",
       " ']',\n",
       " ',',\n",
       " ':',\n",
       " ')',\n",
       " ':',\n",
       " ',',\n",
       " '[',\n",
       " ']',\n",
       " ',',\n",
       " '(',\n",
       " '(',\n",
       " ')',\n",
       " ')',\n",
       " ':',\n",
       " '[',\n",
       " '[',\n",
       " ']',\n",
       " ']',\n",
       " '[',\n",
       " ']',\n",
       " ':',\n",
       " '(',\n",
       " ')',\n",
       " ':',\n",
       " '(',\n",
       " ',',\n",
       " '[',\n",
       " ']',\n",
       " ')',\n",
       " '(',\n",
       " ')',\n",
       " ':',\n",
       " '(',\n",
       " ',',\n",
       " ')',\n",
       " ':',\n",
       " '[',\n",
       " ']',\n",
       " '(',\n",
       " ',',\n",
       " ')',\n",
       " ':',\n",
       " '(',\n",
       " ')',\n",
       " '(',\n",
       " ')',\n",
       " ':',\n",
       " '(',\n",
       " ')',\n",
       " ',',\n",
       " '(',\n",
       " ',',\n",
       " '(',\n",
       " ')',\n",
       " '(',\n",
       " ')',\n",
       " ')',\n",
       " '[',\n",
       " '(',\n",
       " ')',\n",
       " ']',\n",
       " '(',\n",
       " ',',\n",
       " ')',\n",
       " ':',\n",
       " '[',\n",
       " ']',\n",
       " '(',\n",
       " ')',\n",
       " '(',\n",
       " ')',\n",
       " ':',\n",
       " ',',\n",
       " '(',\n",
       " ',',\n",
       " '(',\n",
       " ')',\n",
       " '(',\n",
       " ')',\n",
       " ')',\n",
       " '[',\n",
       " ']',\n",
       " '(',\n",
       " '[',\n",
       " ']',\n",
       " ')',\n",
       " '(',\n",
       " '(',\n",
       " ')',\n",
       " ')',\n",
       " '(',\n",
       " '(',\n",
       " ')',\n",
       " ')',\n",
       " '(',\n",
       " '[',\n",
       " ']',\n",
       " ')',\n",
       " '[',\n",
       " ']',\n",
       " ':',\n",
       " '(',\n",
       " ')',\n",
       " ':',\n",
       " '(',\n",
       " ')',\n",
       " '(',\n",
       " ')',\n",
       " ':',\n",
       " '(',\n",
       " ')',\n",
       " ':',\n",
       " '(',\n",
       " ')',\n",
       " '(',\n",
       " ')',\n",
       " ':',\n",
       " ':',\n",
       " ':',\n",
       " '(',\n",
       " '(',\n",
       " ')',\n",
       " ')',\n",
       " '(',\n",
       " ')',\n",
       " '(',\n",
       " '(',\n",
       " ')',\n",
       " ')',\n",
       " '(',\n",
       " '(',\n",
       " ')',\n",
       " ')',\n",
       " '(',\n",
       " '(',\n",
       " ')',\n",
       " ')',\n",
       " '(',\n",
       " '(',\n",
       " ')',\n",
       " ')',\n",
       " '(',\n",
       " '(',\n",
       " ')',\n",
       " ')',\n",
       " '(',\n",
       " '(',\n",
       " ')',\n",
       " ')',\n",
       " '(',\n",
       " '(',\n",
       " ')',\n",
       " ')',\n",
       " ':',\n",
       " '(',\n",
       " '(',\n",
       " ')',\n",
       " ')',\n",
       " '(',\n",
       " ')',\n",
       " ':',\n",
       " '(',\n",
       " ')',\n",
       " ':',\n",
       " '(',\n",
       " ')',\n",
       " ':',\n",
       " '(',\n",
       " ')',\n",
       " ':',\n",
       " '(',\n",
       " ')',\n",
       " ':',\n",
       " '(',\n",
       " ')',\n",
       " '[',\n",
       " ']',\n",
       " '(',\n",
       " ')',\n",
       " ':',\n",
       " ',',\n",
       " '(',\n",
       " ',',\n",
       " '(',\n",
       " ')',\n",
       " '(',\n",
       " ')',\n",
       " ')',\n",
       " ',',\n",
       " '(',\n",
       " ',',\n",
       " '(',\n",
       " ')',\n",
       " '(',\n",
       " ')',\n",
       " ')',\n",
       " ',',\n",
       " ',',\n",
       " ',',\n",
       " ',',\n",
       " ',',\n",
       " ',',\n",
       " ',',\n",
       " '(',\n",
       " ')',\n",
       " '(',\n",
       " ')',\n",
       " ':',\n",
       " ',',\n",
       " ',',\n",
       " '(',\n",
       " ')',\n",
       " '(',\n",
       " ')',\n",
       " ':',\n",
       " '(',\n",
       " ')',\n",
       " ':',\n",
       " '(',\n",
       " ')',\n",
       " ':',\n",
       " '(',\n",
       " ')',\n",
       " ':',\n",
       " '(',\n",
       " ')',\n",
       " ':',\n",
       " ':',\n",
       " ':',\n",
       " ',',\n",
       " ',',\n",
       " '(',\n",
       " '(',\n",
       " ',',\n",
       " '(',\n",
       " ')',\n",
       " '(',\n",
       " ')',\n",
       " ')',\n",
       " ')',\n",
       " ':',\n",
       " '(',\n",
       " ')',\n",
       " ':',\n",
       " '(',\n",
       " '(',\n",
       " ',',\n",
       " ')',\n",
       " ')',\n",
       " ':',\n",
       " ':',\n",
       " ':',\n",
       " '(',\n",
       " ')',\n",
       " ':',\n",
       " '(',\n",
       " ')',\n",
       " '(',\n",
       " ')',\n",
       " ':',\n",
       " '[',\n",
       " ':',\n",
       " ':',\n",
       " ']',\n",
       " '(',\n",
       " '(',\n",
       " ')',\n",
       " ')',\n",
       " '(',\n",
       " ')',\n",
       " ':',\n",
       " ',',\n",
       " ',',\n",
       " ',',\n",
       " '(',\n",
       " ',',\n",
       " '(',\n",
       " ')',\n",
       " '(',\n",
       " ')',\n",
       " ')',\n",
       " '(',\n",
       " ',',\n",
       " ',',\n",
       " ',',\n",
       " ')',\n",
       " ':',\n",
       " '(',\n",
       " ')',\n",
       " ':',\n",
       " '(',\n",
       " ')',\n",
       " '(',\n",
       " ',',\n",
       " ':',\n",
       " ')',\n",
       " ':',\n",
       " ':',\n",
       " '[',\n",
       " '(',\n",
       " ')',\n",
       " ']',\n",
       " '[',\n",
       " ']',\n",
       " ',',\n",
       " '[',\n",
       " ']',\n",
       " ',',\n",
       " '(',\n",
       " ',',\n",
       " ')',\n",
       " ':',\n",
       " '[',\n",
       " ']',\n",
       " '[',\n",
       " ']',\n",
       " '[',\n",
       " ']',\n",
       " '[',\n",
       " ']',\n",
       " '(',\n",
       " ')',\n",
       " ':',\n",
       " '[',\n",
       " '[',\n",
       " ']',\n",
       " ',',\n",
       " '[',\n",
       " ',',\n",
       " ']',\n",
       " ']',\n",
       " ':',\n",
       " ':',\n",
       " '(',\n",
       " ',',\n",
       " ':',\n",
       " ')',\n",
       " ':',\n",
       " '[',\n",
       " '(',\n",
       " ')',\n",
       " ']',\n",
       " '[',\n",
       " ']',\n",
       " ',',\n",
       " '[',\n",
       " ']',\n",
       " ',',\n",
       " '(',\n",
       " ',',\n",
       " ')',\n",
       " ':',\n",
       " '[',\n",
       " ']',\n",
       " '[',\n",
       " ']',\n",
       " '[',\n",
       " ']',\n",
       " '[',\n",
       " ']',\n",
       " '(',\n",
       " ')',\n",
       " ':',\n",
       " '[',\n",
       " ',',\n",
       " ']',\n",
       " '[',\n",
       " '[',\n",
       " ']',\n",
       " ',',\n",
       " '[',\n",
       " ']',\n",
       " ']',\n",
       " '[',\n",
       " ',',\n",
       " ']',\n",
       " ':',\n",
       " '(',\n",
       " ',',\n",
       " ':',\n",
       " ')',\n",
       " ':',\n",
       " '[',\n",
       " '(',\n",
       " ')',\n",
       " ']',\n",
       " '[',\n",
       " ']',\n",
       " ',',\n",
       " '[',\n",
       " ']',\n",
       " ',',\n",
       " '(',\n",
       " ',',\n",
       " ')',\n",
       " ':',\n",
       " '[',\n",
       " ']',\n",
       " '[',\n",
       " ']',\n",
       " '[',\n",
       " ']',\n",
       " '[',\n",
       " ']',\n",
       " '(',\n",
       " ')',\n",
       " '[',\n",
       " '(',\n",
       " '(',\n",
       " ',',\n",
       " '(',\n",
       " ')',\n",
       " '(',\n",
       " ')',\n",
       " ')',\n",
       " ')',\n",
       " '(',\n",
       " ')',\n",
       " ']',\n",
       " ':',\n",
       " '(',\n",
       " ')',\n",
       " ':',\n",
       " '(',\n",
       " ')',\n",
       " ':',\n",
       " '(',\n",
       " ',',\n",
       " ')',\n",
       " '(',\n",
       " ')',\n",
       " ':',\n",
       " '(',\n",
       " ')',\n",
       " ':',\n",
       " '(',\n",
       " ')',\n",
       " ':',\n",
       " '(',\n",
       " ')',\n",
       " ':',\n",
       " '(',\n",
       " '(',\n",
       " '(',\n",
       " ')',\n",
       " ')',\n",
       " '(',\n",
       " ')',\n",
       " ',',\n",
       " ')',\n",
       " '(',\n",
       " ')',\n",
       " ':',\n",
       " '(',\n",
       " ')',\n",
       " ':',\n",
       " '(',\n",
       " ')',\n",
       " ':',\n",
       " '(',\n",
       " ')',\n",
       " ':',\n",
       " '(',\n",
       " '(',\n",
       " '(',\n",
       " ')',\n",
       " ')',\n",
       " '(',\n",
       " ')',\n",
       " ',',\n",
       " ')',\n",
       " '(',\n",
       " ')',\n",
       " ':',\n",
       " ':',\n",
       " '(',\n",
       " ')',\n",
       " ';',\n",
       " '(',\n",
       " ')',\n",
       " '{',\n",
       " ',',\n",
       " ',',\n",
       " ';',\n",
       " ';',\n",
       " '(',\n",
       " ')',\n",
       " '{',\n",
       " '(',\n",
       " ';',\n",
       " ';',\n",
       " ')',\n",
       " '{',\n",
       " '(',\n",
       " ';',\n",
       " ';',\n",
       " ')',\n",
       " '{',\n",
       " '(',\n",
       " ')',\n",
       " ';',\n",
       " '}',\n",
       " ';',\n",
       " '}',\n",
       " '}',\n",
       " '{',\n",
       " ';',\n",
       " ';',\n",
       " '(',\n",
       " ';',\n",
       " ';',\n",
       " ')',\n",
       " '{',\n",
       " '(',\n",
       " ';',\n",
       " ';',\n",
       " ')',\n",
       " '{',\n",
       " '(',\n",
       " ')',\n",
       " '{',\n",
       " ';',\n",
       " ';',\n",
       " '}',\n",
       " '(',\n",
       " ')',\n",
       " '{',\n",
       " '(',\n",
       " ')',\n",
       " '(',\n",
       " ',',\n",
       " '(',\n",
       " ',',\n",
       " ',',\n",
       " ')',\n",
       " ':',\n",
       " '(',\n",
       " '(',\n",
       " ',',\n",
       " ')',\n",
       " ')',\n",
       " '(',\n",
       " ',',\n",
       " ')',\n",
       " ':',\n",
       " ':',\n",
       " ':',\n",
       " '(',\n",
       " '(',\n",
       " '[',\n",
       " ',',\n",
       " ',',\n",
       " ',',\n",
       " ']',\n",
       " ',',\n",
       " ')',\n",
       " ')',\n",
       " '(',\n",
       " '(',\n",
       " '[',\n",
       " ',',\n",
       " ',',\n",
       " ']',\n",
       " ',',\n",
       " ')',\n",
       " ')',\n",
       " '[',\n",
       " '[',\n",
       " ',',\n",
       " ',',\n",
       " ']',\n",
       " ',',\n",
       " '[',\n",
       " ',',\n",
       " ',',\n",
       " ']',\n",
       " ',',\n",
       " '[',\n",
       " ',',\n",
       " ',',\n",
       " ']',\n",
       " ',',\n",
       " '[',\n",
       " ',',\n",
       " ',',\n",
       " ']',\n",
       " ']',\n",
       " '(',\n",
       " ')',\n",
       " '(',\n",
       " ',',\n",
       " '[',\n",
       " ']',\n",
       " ')',\n",
       " '(',\n",
       " ')',\n",
       " '(',\n",
       " ',',\n",
       " '(',\n",
       " ')',\n",
       " ')',\n",
       " '[',\n",
       " ',',\n",
       " ',',\n",
       " ',',\n",
       " ',',\n",
       " ',',\n",
       " ',',\n",
       " ',',\n",
       " ',',\n",
       " ',',\n",
       " ',',\n",
       " ',',\n",
       " ',',\n",
       " ',',\n",
       " ',',\n",
       " ']',\n",
       " '(',\n",
       " ',',\n",
       " ')',\n",
       " '(',\n",
       " '(',\n",
       " ')',\n",
       " ')',\n",
       " '(',\n",
       " ')',\n",
       " '(',\n",
       " ',',\n",
       " '[',\n",
       " ']',\n",
       " ')',\n",
       " '(',\n",
       " ',',\n",
       " ',',\n",
       " ')',\n",
       " ':',\n",
       " ':',\n",
       " ':',\n",
       " '[',\n",
       " ',',\n",
       " ',',\n",
       " ',',\n",
       " ',',\n",
       " ',',\n",
       " ',',\n",
       " ',',\n",
       " ',',\n",
       " ']',\n",
       " '(',\n",
       " '(',\n",
       " ',',\n",
       " ',',\n",
       " ')',\n",
       " ')',\n",
       " '[',\n",
       " ',',\n",
       " ',',\n",
       " ',',\n",
       " ',',\n",
       " ',',\n",
       " ']',\n",
       " '(',\n",
       " '(',\n",
       " ',',\n",
       " ',',\n",
       " ')',\n",
       " ')',\n",
       " '(',\n",
       " ',',\n",
       " ',',\n",
       " ')',\n",
       " ':',\n",
       " ':',\n",
       " ':',\n",
       " '[',\n",
       " ',',\n",
       " ',',\n",
       " ',',\n",
       " ',',\n",
       " ',',\n",
       " ',',\n",
       " ',',\n",
       " ',',\n",
       " ']',\n",
       " '(',\n",
       " '(',\n",
       " ',',\n",
       " ',',\n",
       " ')',\n",
       " ')',\n",
       " '[',\n",
       " ',',\n",
       " ',',\n",
       " ',',\n",
       " ',',\n",
       " ',',\n",
       " ']',\n",
       " '(',\n",
       " '(',\n",
       " ',',\n",
       " ')',\n",
       " ':',\n",
       " '(',\n",
       " ')',\n",
       " '(',\n",
       " ')',\n",
       " ':',\n",
       " '(',\n",
       " ')',\n",
       " '(',\n",
       " ')',\n",
       " ':',\n",
       " ':',\n",
       " '(',\n",
       " ')',\n",
       " ':',\n",
       " '(',\n",
       " ')',\n",
       " '(',\n",
       " ',',\n",
       " ...]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flatten_list([[t for t, b in tbs if b == \"Punctuation\"] for tbs in tqdm(D_machine_tr[\"text_base\"])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "31d7da86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "69742"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build features\n",
    "len(Counter(flatten_list(D_tr[\"text_base\"].to_list())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "856b00d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def identity_fn(x):\n",
    "    return x\n",
    "\n",
    "plid_vectorizer = TfidfVectorizer(\n",
    "    vocabulary=VOCAB_FOR_PLID,\n",
    "    analyzer=identity_fn,\n",
    "    lowercase=False,\n",
    "    norm=None,\n",
    "    use_idf=True,\n",
    "    smooth_idf=True,\n",
    ").fit(D_tr[\"text_base\"].to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "f4ad3ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr = plid_vectorizer.transform(D_tr[\"text_base\"].to_list())\n",
    "X_ev = plid_vectorizer.transform(D_ev[\"text_base\"].to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "609d0377",
   "metadata": {},
   "outputs": [],
   "source": [
    "plid = LogisticRegression(\n",
    "    penalty=\"l2\",\n",
    "    C=1.0,\n",
    "    solver=\"lbfgs\",\n",
    "    max_iter=1000,\n",
    "    random_state=888,\n",
    ").fit(X_tr, D_tr[\"language\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "eb7cc1e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         C++       0.98      0.97      0.98       459\n",
      "        Java       0.97      0.97      0.97       413\n",
      "      Python       1.00      1.00      1.00      9128\n",
      "\n",
      "    accuracy                           1.00     10000\n",
      "   macro avg       0.99      0.98      0.98     10000\n",
      "weighted avg       1.00      1.00      1.00     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(D_ev[\"language\"], plid.predict(X_ev)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c1c19f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "036164f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "672e7fbe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b0afb56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fe83b56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f75759",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0637d26c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python\n",
      "Java\n",
      "C++\n"
     ]
    }
   ],
   "source": [
    "for lang in D_tr[\"language\"].unique():\n",
    "    D_tr_sub = D_tr[D_tr[\"language\"] == lang]\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "7dd8f722",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "132"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(VOCAB_FOR_PLID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "230c5213",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code</th>\n",
       "      <th>generator</th>\n",
       "      <th>label</th>\n",
       "      <th>language</th>\n",
       "      <th>token_obj</th>\n",
       "      <th>tokens</th>\n",
       "      <th>base_type</th>\n",
       "      <th>text</th>\n",
       "      <th>base</th>\n",
       "      <th>text_base</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>361965</th>\n",
       "      <td>t = int(input())\\nfor _ in range(t):\\n\\tk = [l...</td>\n",
       "      <td>human</td>\n",
       "      <td>0</td>\n",
       "      <td>Python</td>\n",
       "      <td>{'language': 'Python', 'tokens': [{'text': 't'...</td>\n",
       "      <td>[{'text': 't', 'type': 'Token.Name', 'base_typ...</td>\n",
       "      <td>[Name, Text, Operator, Text, Name, Punctuation...</td>\n",
       "      <td>[t,  , =,  , int, (, input, (, ), ), \\n, for, ...</td>\n",
       "      <td>[Name, Text, Operator, Text, Name, Punctuation...</td>\n",
       "      <td>[t&lt;-&gt;Name,  &lt;-&gt;Text, =&lt;-&gt;Operator,  &lt;-&gt;Text, i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179837</th>\n",
       "      <td>import static java.lang.Math.max;\\n\\nimport st...</td>\n",
       "      <td>human</td>\n",
       "      <td>0</td>\n",
       "      <td>Java</td>\n",
       "      <td>{'language': 'Java', 'tokens': [{'text': 'impo...</td>\n",
       "      <td>[{'text': 'import static', 'type': 'Token.Keyw...</td>\n",
       "      <td>[Keyword, Text, Name, Punctuation, Text, Text,...</td>\n",
       "      <td>[import static,  , java.lang.Math.max, ;, \\n, ...</td>\n",
       "      <td>[Keyword, Text, Name, Punctuation, Text, Text,...</td>\n",
       "      <td>[import static&lt;-&gt;Keyword,  &lt;-&gt;Text, java.lang....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>472639</th>\n",
       "      <td>(n, *a) = map(int, open(0).read().split())\\nm ...</td>\n",
       "      <td>human</td>\n",
       "      <td>0</td>\n",
       "      <td>Python</td>\n",
       "      <td>{'language': 'Python', 'tokens': [{'text': '('...</td>\n",
       "      <td>[{'text': '(', 'type': 'Token.Punctuation', 'b...</td>\n",
       "      <td>[Punctuation, Name, Punctuation, Text, Operato...</td>\n",
       "      <td>[(, n, ,,  , *, a, ),  , =,  , map, (, int, ,,...</td>\n",
       "      <td>[Punctuation, Name, Punctuation, Text, Operato...</td>\n",
       "      <td>[(&lt;-&gt;Punctuation, n&lt;-&gt;Name, ,&lt;-&gt;Punctuation,  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97298</th>\n",
       "      <td>from collections import defaultdict\\n\\ndef are...</td>\n",
       "      <td>human</td>\n",
       "      <td>0</td>\n",
       "      <td>Python</td>\n",
       "      <td>{'language': 'Python', 'tokens': [{'text': 'fr...</td>\n",
       "      <td>[{'text': 'from', 'type': 'Token.Keyword.Names...</td>\n",
       "      <td>[Keyword, Text, Name, Text, Keyword, Text, Nam...</td>\n",
       "      <td>[from,  , collections,  , import,  , defaultdi...</td>\n",
       "      <td>[Keyword, Text, Name, Text, Keyword, Text, Nam...</td>\n",
       "      <td>[from&lt;-&gt;Keyword,  &lt;-&gt;Text, collections&lt;-&gt;Name,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276933</th>\n",
       "      <td>n = int(input())\\n(v, a) = ([0] * n, [0] * n)\\...</td>\n",
       "      <td>human</td>\n",
       "      <td>0</td>\n",
       "      <td>Python</td>\n",
       "      <td>{'language': 'Python', 'tokens': [{'text': 'n'...</td>\n",
       "      <td>[{'text': 'n', 'type': 'Token.Name', 'base_typ...</td>\n",
       "      <td>[Name, Text, Operator, Text, Name, Punctuation...</td>\n",
       "      <td>[n,  , =,  , int, (, input, (, ), ), \\n, (, v,...</td>\n",
       "      <td>[Name, Text, Operator, Text, Name, Punctuation...</td>\n",
       "      <td>[n&lt;-&gt;Name,  &lt;-&gt;Text, =&lt;-&gt;Operator,  &lt;-&gt;Text, i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>448969</th>\n",
       "      <td>bisect.bisect_left can be helpful in finding v...</td>\n",
       "      <td>microsoft/phi-2</td>\n",
       "      <td>1</td>\n",
       "      <td>Python</td>\n",
       "      <td>{'language': 'Python', 'tokens': [{'text': 'bi...</td>\n",
       "      <td>[{'text': 'bisect', 'type': 'Token.Name', 'bas...</td>\n",
       "      <td>[Name, Operator, Name, Text, Name, Text, Name,...</td>\n",
       "      <td>[bisect, ., bisect_left,  , can,  , be,  , hel...</td>\n",
       "      <td>[Name, Operator, Name, Text, Name, Text, Name,...</td>\n",
       "      <td>[bisect&lt;-&gt;Name, .&lt;-&gt;Operator, bisect_left&lt;-&gt;Na...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416400</th>\n",
       "      <td>, don't print anything.\\ndef beautiful_string_...</td>\n",
       "      <td>Qwen/Qwen2.5-Coder-1.5B</td>\n",
       "      <td>1</td>\n",
       "      <td>Python</td>\n",
       "      <td>{'language': 'Python', 'tokens': [{'text': ','...</td>\n",
       "      <td>[{'text': ',', 'type': 'Token.Punctuation', 'b...</td>\n",
       "      <td>[Punctuation, Text, Name, Literal, Literal, Te...</td>\n",
       "      <td>[,,  , don, ', t print anything., \\n, def,  , ...</td>\n",
       "      <td>[Punctuation, Text, Name, Literal, Literal, Te...</td>\n",
       "      <td>[,&lt;-&gt;Punctuation,  &lt;-&gt;Text, don&lt;-&gt;Name, '&lt;-&gt;Li...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61662</th>\n",
       "      <td>const int MAXN = 300005;\\n\\nnamespace Trie {\\n...</td>\n",
       "      <td>human</td>\n",
       "      <td>0</td>\n",
       "      <td>C++</td>\n",
       "      <td>{'language': 'C++', 'tokens': [{'text': 'const...</td>\n",
       "      <td>[{'text': 'const', 'type': 'Token.Keyword', 'b...</td>\n",
       "      <td>[Keyword, Text, Keyword, Text, Name, Text, Ope...</td>\n",
       "      <td>[const,  , int,  , MAXN,  , =,  , 300005, ;, \\...</td>\n",
       "      <td>[Keyword, Text, Keyword, Text, Name, Text, Ope...</td>\n",
       "      <td>[const&lt;-&gt;Keyword,  &lt;-&gt;Text, int&lt;-&gt;Keyword,  &lt;-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337637</th>\n",
       "      <td>python\\n\\ndef min_rectangle_cover(points):\\n  ...</td>\n",
       "      <td>01-ai/Yi-Coder-9B-Chat</td>\n",
       "      <td>1</td>\n",
       "      <td>Python</td>\n",
       "      <td>{'language': 'Python', 'tokens': [{'text': 'py...</td>\n",
       "      <td>[{'text': 'python', 'type': 'Token.Name', 'bas...</td>\n",
       "      <td>[Name, Text, Text, Keyword, Text, Name, Punctu...</td>\n",
       "      <td>[python, \\n, \\n, def,  , min_rectangle_cover, ...</td>\n",
       "      <td>[Name, Text, Text, Keyword, Text, Name, Punctu...</td>\n",
       "      <td>[python&lt;-&gt;Name, \\n&lt;-&gt;Text, \\n&lt;-&gt;Text, def&lt;-&gt;Ke...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72972</th>\n",
       "      <td>for _ in range(int(input())):\\n\\ts = input()\\n...</td>\n",
       "      <td>human</td>\n",
       "      <td>0</td>\n",
       "      <td>Python</td>\n",
       "      <td>{'language': 'Python', 'tokens': [{'text': 'fo...</td>\n",
       "      <td>[{'text': 'for', 'type': 'Token.Keyword', 'bas...</td>\n",
       "      <td>[Keyword, Text, Name, Text, Operator, Text, Na...</td>\n",
       "      <td>[for,  , _,  , in,  , range, (, int, (, input,...</td>\n",
       "      <td>[Keyword, Text, Name, Text, Operator, Text, Na...</td>\n",
       "      <td>[for&lt;-&gt;Keyword,  &lt;-&gt;Text, _&lt;-&gt;Name,  &lt;-&gt;Text, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     code  \\\n",
       "361965  t = int(input())\\nfor _ in range(t):\\n\\tk = [l...   \n",
       "179837  import static java.lang.Math.max;\\n\\nimport st...   \n",
       "472639  (n, *a) = map(int, open(0).read().split())\\nm ...   \n",
       "97298   from collections import defaultdict\\n\\ndef are...   \n",
       "276933  n = int(input())\\n(v, a) = ([0] * n, [0] * n)\\...   \n",
       "...                                                   ...   \n",
       "448969  bisect.bisect_left can be helpful in finding v...   \n",
       "416400  , don't print anything.\\ndef beautiful_string_...   \n",
       "61662   const int MAXN = 300005;\\n\\nnamespace Trie {\\n...   \n",
       "337637  python\\n\\ndef min_rectangle_cover(points):\\n  ...   \n",
       "72972   for _ in range(int(input())):\\n\\ts = input()\\n...   \n",
       "\n",
       "                      generator  label language  \\\n",
       "361965                    human      0   Python   \n",
       "179837                    human      0     Java   \n",
       "472639                    human      0   Python   \n",
       "97298                     human      0   Python   \n",
       "276933                    human      0   Python   \n",
       "...                         ...    ...      ...   \n",
       "448969          microsoft/phi-2      1   Python   \n",
       "416400  Qwen/Qwen2.5-Coder-1.5B      1   Python   \n",
       "61662                     human      0      C++   \n",
       "337637   01-ai/Yi-Coder-9B-Chat      1   Python   \n",
       "72972                     human      0   Python   \n",
       "\n",
       "                                                token_obj  \\\n",
       "361965  {'language': 'Python', 'tokens': [{'text': 't'...   \n",
       "179837  {'language': 'Java', 'tokens': [{'text': 'impo...   \n",
       "472639  {'language': 'Python', 'tokens': [{'text': '('...   \n",
       "97298   {'language': 'Python', 'tokens': [{'text': 'fr...   \n",
       "276933  {'language': 'Python', 'tokens': [{'text': 'n'...   \n",
       "...                                                   ...   \n",
       "448969  {'language': 'Python', 'tokens': [{'text': 'bi...   \n",
       "416400  {'language': 'Python', 'tokens': [{'text': ','...   \n",
       "61662   {'language': 'C++', 'tokens': [{'text': 'const...   \n",
       "337637  {'language': 'Python', 'tokens': [{'text': 'py...   \n",
       "72972   {'language': 'Python', 'tokens': [{'text': 'fo...   \n",
       "\n",
       "                                                   tokens  \\\n",
       "361965  [{'text': 't', 'type': 'Token.Name', 'base_typ...   \n",
       "179837  [{'text': 'import static', 'type': 'Token.Keyw...   \n",
       "472639  [{'text': '(', 'type': 'Token.Punctuation', 'b...   \n",
       "97298   [{'text': 'from', 'type': 'Token.Keyword.Names...   \n",
       "276933  [{'text': 'n', 'type': 'Token.Name', 'base_typ...   \n",
       "...                                                   ...   \n",
       "448969  [{'text': 'bisect', 'type': 'Token.Name', 'bas...   \n",
       "416400  [{'text': ',', 'type': 'Token.Punctuation', 'b...   \n",
       "61662   [{'text': 'const', 'type': 'Token.Keyword', 'b...   \n",
       "337637  [{'text': 'python', 'type': 'Token.Name', 'bas...   \n",
       "72972   [{'text': 'for', 'type': 'Token.Keyword', 'bas...   \n",
       "\n",
       "                                                base_type  \\\n",
       "361965  [Name, Text, Operator, Text, Name, Punctuation...   \n",
       "179837  [Keyword, Text, Name, Punctuation, Text, Text,...   \n",
       "472639  [Punctuation, Name, Punctuation, Text, Operato...   \n",
       "97298   [Keyword, Text, Name, Text, Keyword, Text, Nam...   \n",
       "276933  [Name, Text, Operator, Text, Name, Punctuation...   \n",
       "...                                                   ...   \n",
       "448969  [Name, Operator, Name, Text, Name, Text, Name,...   \n",
       "416400  [Punctuation, Text, Name, Literal, Literal, Te...   \n",
       "61662   [Keyword, Text, Keyword, Text, Name, Text, Ope...   \n",
       "337637  [Name, Text, Text, Keyword, Text, Name, Punctu...   \n",
       "72972   [Keyword, Text, Name, Text, Operator, Text, Na...   \n",
       "\n",
       "                                                     text  \\\n",
       "361965  [t,  , =,  , int, (, input, (, ), ), \\n, for, ...   \n",
       "179837  [import static,  , java.lang.Math.max, ;, \\n, ...   \n",
       "472639  [(, n, ,,  , *, a, ),  , =,  , map, (, int, ,,...   \n",
       "97298   [from,  , collections,  , import,  , defaultdi...   \n",
       "276933  [n,  , =,  , int, (, input, (, ), ), \\n, (, v,...   \n",
       "...                                                   ...   \n",
       "448969  [bisect, ., bisect_left,  , can,  , be,  , hel...   \n",
       "416400  [,,  , don, ', t print anything., \\n, def,  , ...   \n",
       "61662   [const,  , int,  , MAXN,  , =,  , 300005, ;, \\...   \n",
       "337637  [python, \\n, \\n, def,  , min_rectangle_cover, ...   \n",
       "72972   [for,  , _,  , in,  , range, (, int, (, input,...   \n",
       "\n",
       "                                                     base  \\\n",
       "361965  [Name, Text, Operator, Text, Name, Punctuation...   \n",
       "179837  [Keyword, Text, Name, Punctuation, Text, Text,...   \n",
       "472639  [Punctuation, Name, Punctuation, Text, Operato...   \n",
       "97298   [Keyword, Text, Name, Text, Keyword, Text, Nam...   \n",
       "276933  [Name, Text, Operator, Text, Name, Punctuation...   \n",
       "...                                                   ...   \n",
       "448969  [Name, Operator, Name, Text, Name, Text, Name,...   \n",
       "416400  [Punctuation, Text, Name, Literal, Literal, Te...   \n",
       "61662   [Keyword, Text, Keyword, Text, Name, Text, Ope...   \n",
       "337637  [Name, Text, Text, Keyword, Text, Name, Punctu...   \n",
       "72972   [Keyword, Text, Name, Text, Operator, Text, Na...   \n",
       "\n",
       "                                                text_base  \n",
       "361965  [t<->Name,  <->Text, =<->Operator,  <->Text, i...  \n",
       "179837  [import static<->Keyword,  <->Text, java.lang....  \n",
       "472639  [(<->Punctuation, n<->Name, ,<->Punctuation,  ...  \n",
       "97298   [from<->Keyword,  <->Text, collections<->Name,...  \n",
       "276933  [n<->Name,  <->Text, =<->Operator,  <->Text, i...  \n",
       "...                                                   ...  \n",
       "448969  [bisect<->Name, .<->Operator, bisect_left<->Na...  \n",
       "416400  [,<->Punctuation,  <->Text, don<->Name, '<->Li...  \n",
       "61662   [const<->Keyword,  <->Text, int<->Keyword,  <-...  \n",
       "337637  [python<->Name, \\n<->Text, \\n<->Text, def<->Ke...  \n",
       "72972   [for<->Keyword,  <->Text, _<->Name,  <->Text, ...  \n",
       "\n",
       "[10000 rows x 10 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D_tr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d1b07cef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['t<->Name',\n",
       " ' <->Text',\n",
       " '=<->Operator',\n",
       " ' <->Text',\n",
       " 'int<->Name',\n",
       " '(<->Punctuation',\n",
       " 'input<->Name',\n",
       " '(<->Punctuation',\n",
       " ')<->Punctuation',\n",
       " ')<->Punctuation',\n",
       " '\\n<->Text',\n",
       " 'for<->Keyword',\n",
       " ' <->Text',\n",
       " '_<->Name',\n",
       " ' <->Text',\n",
       " 'in<->Operator',\n",
       " ' <->Text',\n",
       " 'range<->Name',\n",
       " '(<->Punctuation',\n",
       " 't<->Name',\n",
       " ')<->Punctuation',\n",
       " ':<->Punctuation',\n",
       " '\\n<->Text',\n",
       " '\\t<->Text',\n",
       " 'k<->Name',\n",
       " ' <->Text',\n",
       " '=<->Operator',\n",
       " ' <->Text',\n",
       " '[<->Punctuation',\n",
       " 'len<->Name',\n",
       " '(<->Punctuation',\n",
       " 'x<->Name',\n",
       " ')<->Punctuation',\n",
       " ' <->Text',\n",
       " 'for<->Keyword',\n",
       " ' <->Text',\n",
       " 'x<->Name',\n",
       " ' <->Text',\n",
       " 'in<->Operator',\n",
       " ' <->Text',\n",
       " 'input<->Name',\n",
       " '(<->Punctuation',\n",
       " ')<->Punctuation',\n",
       " '.<->Operator',\n",
       " 'split<->Name',\n",
       " '(<->Punctuation',\n",
       " \"'<->Literal\",\n",
       " 'R<->Literal',\n",
       " \"'<->Literal\",\n",
       " ')<->Punctuation',\n",
       " ']<->Punctuation',\n",
       " '\\n<->Text',\n",
       " '\\t<->Text',\n",
       " 'print<->Name',\n",
       " '(<->Punctuation',\n",
       " 'max<->Name',\n",
       " '(<->Punctuation',\n",
       " 'k<->Name',\n",
       " ')<->Punctuation',\n",
       " ' <->Text',\n",
       " '+<->Operator',\n",
       " ' <->Text',\n",
       " '1<->Literal',\n",
       " ')<->Punctuation',\n",
       " '\\n<->Text',\n",
       " 'import static<->Keyword',\n",
       " ' <->Text',\n",
       " 'java.lang.Math.max<->Name',\n",
       " ';<->Punctuation',\n",
       " '\\n<->Text',\n",
       " '\\n<->Text',\n",
       " 'import static<->Keyword',\n",
       " ' <->Text',\n",
       " 'java.lang.Math.min<->Name',\n",
       " ';<->Punctuation',\n",
       " '\\n<->Text',\n",
       " '\\n<->Text',\n",
       " 'import static<->Keyword',\n",
       " ' <->Text',\n",
       " 'java.lang.Math.abs<->Name',\n",
       " ';<->Punctuation',\n",
       " '\\n<->Text',\n",
       " '\\n<->Text',\n",
       " '\\n<->Text',\n",
       " '\\n<->Text',\n",
       " 'import<->Keyword',\n",
       " ' <->Text',\n",
       " 'java.util.*<->Name',\n",
       " ';<->Punctuation',\n",
       " '\\n<->Text',\n",
       " '\\n<->Text',\n",
       " 'import<->Keyword',\n",
       " ' <->Text',\n",
       " 'java.io.*<->Name',\n",
       " ';<->Punctuation',\n",
       " '\\n<->Text',\n",
       " '\\n<->Text',\n",
       " 'import<->Keyword',\n",
       " ' <->Text',\n",
       " 'java.math.*<->Name',\n",
       " ';<->Punctuation',\n",
       " '\\n<->Text',\n",
       " '\\n<->Text',\n",
       " '\\n<->Text',\n",
       " '\\n<->Text',\n",
       " '\\n<->Text',\n",
       " '\\n<->Text',\n",
       " 'public<->Keyword',\n",
       " ' <->Text',\n",
       " 'class<->Keyword',\n",
       " ' <->Text',\n",
       " 'A_Median_Maximization<->Name',\n",
       " ' <->Text',\n",
       " '{<->Punctuation',\n",
       " '\\n<->Text',\n",
       " '\\n<->Text',\n",
       " '\\n<->Text',\n",
       " '\\n<->Text',\n",
       " '    <->Text',\n",
       " 'public<->Keyword',\n",
       " ' <->Text',\n",
       " 'static<->Keyword',\n",
       " ' <->Text',\n",
       " 'void<->Keyword',\n",
       " ' <->Text',\n",
       " 'main<->Name',\n",
       " '(<->Punctuation',\n",
       " 'String<->Name',\n",
       " '[<->Operator',\n",
       " ']<->Operator',\n",
       " ' <->Text',\n",
       " 'args<->Name',\n",
       " ')<->Punctuation',\n",
       " ' <->Text',\n",
       " '{<->Punctuation',\n",
       " '\\n<->Text',\n",
       " '\\n<->Text',\n",
       " '        <->Text',\n",
       " 'OutputStream<->Name',\n",
       " ' <->Text',\n",
       " 'outputStream<->Name',\n",
       " ' <->Text',\n",
       " '=<->Operator',\n",
       " ' <->Text',\n",
       " 'System<->Name',\n",
       " '.<->Punctuation',\n",
       " 'out<->Name',\n",
       " ';<->Punctuation',\n",
       " '\\n<->Text',\n",
       " '\\n<->Text',\n",
       " '        <->Text',\n",
       " 'PrintWriter<->Name',\n",
       " ' <->Text',\n",
       " 'out<->Name',\n",
       " ' <->Text',\n",
       " '=<->Operator',\n",
       " ' <->Text',\n",
       " 'new<->Keyword',\n",
       " ' <->Text',\n",
       " 'PrintWriter<->Name',\n",
       " '(<->Punctuation',\n",
       " 'outputStream<->Name',\n",
       " ')<->Punctuation',\n",
       " ';<->Punctuation',\n",
       " '\\n<->Text',\n",
       " '\\n<->Text',\n",
       " '        <->Text',\n",
       " 'FastReader<->Name',\n",
       " ' <->Text',\n",
       " 'f<->Name',\n",
       " ' <->Text',\n",
       " '=<->Operator',\n",
       " ' <->Text',\n",
       " 'new<->Keyword',\n",
       " ' <->Text',\n",
       " 'FastReader<->Name',\n",
       " '(<->Punctuation',\n",
       " ')<->Punctuation',\n",
       " ';<->Punctuation',\n",
       " '\\n<->Text',\n",
       " '\\n<->Text',\n",
       " '        <->Text',\n",
       " 'int<->Keyword',\n",
       " ' <->Text',\n",
       " 't<->Name',\n",
       " ' <->Text',\n",
       " '=<->Operator',\n",
       " ' <->Text',\n",
       " 'f<->Name',\n",
       " '.<->Punctuation',\n",
       " 'nextInt<->Name',\n",
       " '(<->Punctuation',\n",
       " ')<->Punctuation',\n",
       " ';<->Punctuation',\n",
       " '\\n<->Text',\n",
       " '\\n<->Text',\n",
       " '\\n<->Text',\n",
       " '\\n<->Text',\n",
       " '        <->Text',\n",
       " 'while<->Keyword',\n",
       " '(<->Punctuation',\n",
       " 't<->Name',\n",
       " '-<->Operator',\n",
       " '-<->Operator',\n",
       " ' <->Text',\n",
       " '><->Operator',\n",
       " ' <->Text',\n",
       " '0<->Literal',\n",
       " ')<->Punctuation',\n",
       " '{<->Punctuation',\n",
       " '\\n<->Text',\n",
       " '\\n<->Text',\n",
       " '            <->Text',\n",
       " 'solve<->Name',\n",
       " '(<->Punctuation',\n",
       " 'f<->Name',\n",
       " ',<->Punctuation',\n",
       " ' <->Text',\n",
       " 'out<->Name',\n",
       " ')<->Punctuation',\n",
       " ';<->Punctuation',\n",
       " '\\n<->Text',\n",
       " '\\n<->Text',\n",
       " '        <->Text',\n",
       " '}<->Punctuation',\n",
       " '\\n<->Text',\n",
       " '\\n<->Text',\n",
       " '\\n<->Text',\n",
       " '\\n<->Text',\n",
       " '\\n<->Text',\n",
       " '\\n<->Text',\n",
       " '        <->Text',\n",
       " 'out<->Name',\n",
       " '.<->Punctuation',\n",
       " 'close<->Name',\n",
       " '(<->Punctuation',\n",
       " ')<->Punctuation',\n",
       " ';<->Punctuation',\n",
       " '\\n<->Text',\n",
       " '\\n<->Text',\n",
       " '    <->Text',\n",
       " '}<->Punctuation',\n",
       " '\\n<->Text',\n",
       " '\\n<->Text',\n",
       " '\\n<->Text',\n",
       " '\\n<->Text',\n",
       " '\\n<->Text',\n",
       " '\\n<->Text',\n",
       " '    <->Text',\n",
       " 'public<->Keyword',\n",
       " ' <->Text',\n",
       " 'static<->Keyword',\n",
       " ' <->Text',\n",
       " 'void<->Keyword',\n",
       " ' <->Text',\n",
       " 'solve<->Name',\n",
       " '(<->Punctuation',\n",
       " 'FastReader<->Name',\n",
       " ' <->Text',\n",
       " 'f<->Name',\n",
       " ',<->Punctuation',\n",
       " ' <->Text',\n",
       " 'PrintWriter<->Name',\n",
       " ' <->Text',\n",
       " 'out<->Name',\n",
       " ')<->Punctuation',\n",
       " ' <->Text',\n",
       " '{<->Punctuation',\n",
       " '\\n<->Text',\n",
       " '\\n<->Text',\n",
       " '        <->Text',\n",
       " 'int<->Keyword',\n",
       " ' <->Text',\n",
       " 'n<->Name',\n",
       " ' <->Text',\n",
       " '=<->Operator',\n",
       " ' <->Text',\n",
       " 'f<->Name',\n",
       " '.<->Punctuation',\n",
       " 'nextInt<->Name',\n",
       " '(<->Punctuation',\n",
       " ')<->Punctuation',\n",
       " ';<->Punctuation',\n",
       " '\\n<->Text',\n",
       " '\\n<->Text',\n",
       " '        <->Text',\n",
       " 'int<->Keyword',\n",
       " ' <->Text',\n",
       " 's<->Name',\n",
       " ' <->Text',\n",
       " '=<->Operator',\n",
       " ' <->Text',\n",
       " 'f<->Name',\n",
       " '.<->Punctuation',\n",
       " 'nextInt<->Name',\n",
       " '(<->Punctuation',\n",
       " ')<->Punctuation',\n",
       " ';<->Punctuation',\n",
       " '\\n<->Text',\n",
       " '\\n<->Text',\n",
       " '\\n<->Text',\n",
       " '\\n<->Text',\n",
       " '        <->Text',\n",
       " 'int<->Keyword',\n",
       " ' <->Text',\n",
       " 'medInd<->Name',\n",
       " ' <->Text',\n",
       " '=<->Operator',\n",
       " ' <->Text',\n",
       " '(<->Punctuation',\n",
       " 'n<->Name',\n",
       " '+<->Operator',\n",
       " '1<->Literal',\n",
       " ')<->Punctuation',\n",
       " '/<->Operator',\n",
       " '2<->Literal',\n",
       " ';<->Punctuation',\n",
       " '\\n<->Text',\n",
       " '\\n<->Text',\n",
       " '\\n<->Text',\n",
       " '\\n<->Text',\n",
       " '        <->Text',\n",
       " 's<->Name',\n",
       " ' <->Text',\n",
       " '/<->Operator',\n",
       " '=<->Operator',\n",
       " ' <->Text',\n",
       " '(<->Punctuation',\n",
       " 'n<->Name',\n",
       " '-<->Operator',\n",
       " 'medInd<->Name',\n",
       " '+<->Operator',\n",
       " '1<->Literal',\n",
       " ')<->Punctuation',\n",
       " ';<->Punctuation',\n",
       " '\\n<->Text',\n",
       " '\\n<->Text',\n",
       " '\\n<->Text',\n",
       " '\\n<->Text',\n",
       " '        <->Text',\n",
       " 'out<->Name',\n",
       " '.<->Punctuation',\n",
       " 'println<->Name',\n",
       " '(<->Punctuation',\n",
       " 's<->Name',\n",
       " ')<->Punctuation',\n",
       " ';<->Punctuation',\n",
       " '\\n<->Text',\n",
       " '\\n<->Text',\n",
       " '    <->Text',\n",
       " '}<->Punctuation',\n",
       " '\\n<->Text',\n",
       " '\\n<->Text',\n",
       " '\\n<->Text',\n",
       " '\\n<->Text',\n",
       " '\\n<->Text',\n",
       " '\\n<->Text',\n",
       " '\\n<->Text',\n",
       " '\\n<->Text',\n",
       " '\\n<->Text',\n",
       " '\\n<->Text',\n",
       " '\\n<->Text',\n",
       " '\\n<->Text',\n",
       " '\\n<->Text',\n",
       " '\\n<->Text',\n",
       " '\\n<->Text',\n",
       " '\\n<->Text',\n",
       " '\\n<->Text',\n",
       " '\\n<->Text',\n",
       " '    <->Text',\n",
       " 'public<->Keyword',\n",
       " ' <->Text',\n",
       " 'static<->Keyword',\n",
       " ' <->Text',\n",
       " 'void<->Keyword',\n",
       " ' <->Text',\n",
       " 'sort<->Name',\n",
       " '(<->Punctuation',\n",
       " 'int<->Keyword',\n",
       " ' <->Text',\n",
       " 'arr<->Name',\n",
       " '[<->Operator',\n",
       " ']<->Operator',\n",
       " ')<->Punctuation',\n",
       " ' <->Text',\n",
       " '{<->Punctuation',\n",
       " '\\n<->Text',\n",
       " '\\n<->Text',\n",
       " '        <->Text',\n",
       " 'ArrayList<->Name',\n",
       " '<<->Operator',\n",
       " 'Integer<->Name',\n",
       " '><->Operator',\n",
       " ' <->Text',\n",
       " 'al<->Name',\n",
       " ' <->Text',\n",
       " '=<->Operator',\n",
       " ' <->Text',\n",
       " 'new<->Keyword',\n",
       " ' <->Text',\n",
       " 'ArrayList<->Name',\n",
       " '<<->Operator',\n",
       " '><->Operator',\n",
       " '(<->Punctuation',\n",
       " ')<->Punctuation',\n",
       " ';<->Punctuation',\n",
       " '\\n<->Text',\n",
       " '\\n<->Text',\n",
       " '        <->Text',\n",
       " 'for<->Keyword',\n",
       " '(<->Punctuation',\n",
       " 'int<->Keyword',\n",
       " ' <->Text',\n",
       " 'i<->Name',\n",
       " ':<->Punctuation',\n",
       " ' <->Text',\n",
       " 'arr<->Name',\n",
       " ')<->Punctuation',\n",
       " ' <->Text',\n",
       " '{<->Punctuation',\n",
       " '\\n<->Text',\n",
       " '\\n<->Text',\n",
       " '            <->Text',\n",
       " 'al<->Name',\n",
       " '.<->Punctuation',\n",
       " 'add<->Name',\n",
       " '(<->Punctuation',\n",
       " 'i<->Name',\n",
       " ')<->Punctuation',\n",
       " ';<->Punctuation',\n",
       " '\\n<->Text',\n",
       " '\\n<->Text',\n",
       " '        <->Text',\n",
       " '}<->Punctuation',\n",
       " '\\n<->Text',\n",
       " '\\n<->Text',\n",
       " '        <->Text',\n",
       " 'Collections<->Name',\n",
       " '.<->Punctuation',\n",
       " 'sort<->Name',\n",
       " '(<->Punctuation',\n",
       " 'al<->Name',\n",
       " ')<->Punctuation',\n",
       " ';<->Punctuation',\n",
       " '\\n<->Text',\n",
       " '\\n<->Text',\n",
       " '        <->Text',\n",
       " 'for<->Keyword',\n",
       " '(<->Punctuation',\n",
       " 'int<->Keyword',\n",
       " ' <->Text',\n",
       " 'i<->Name',\n",
       " ' <->Text',\n",
       " '=<->Operator',\n",
       " ' <->Text',\n",
       " '0<->Literal',\n",
       " ';<->Punctuation',\n",
       " ' <->Text',\n",
       " 'i<->Name',\n",
       " ' <->Text',\n",
       " '<<->Operator',\n",
       " ' <->Text',\n",
       " 'arr<->Name',\n",
       " '.<->Punctuation',\n",
       " 'length<->Name',\n",
       " ';<->Punctuation',\n",
       " ' <->Text',\n",
       " 'i<->Name',\n",
       " '+<->Operator',\n",
       " '+<->Operator',\n",
       " ')<->Punctuation',\n",
       " ' <->Text',\n",
       " '{<->Punctuation',\n",
       " '\\n<->Text',\n",
       " '\\n<->Text',\n",
       " '            <->Text',\n",
       " 'arr<->Name',\n",
       " '[<->Operator',\n",
       " 'i<->Name',\n",
       " ']<->Operator',\n",
       " ' <->Text',\n",
       " '=<->Operator',\n",
       " ' <->Text',\n",
       " 'al<->Name',\n",
       " '.<->Punctuation',\n",
       " 'get<->Name',\n",
       " '(<->Punctuation',\n",
       " 'i<->Name',\n",
       " ')<->Punctuation',\n",
       " ';<->Punctuation',\n",
       " '\\n<->Text',\n",
       " '\\n<->Text',\n",
       " '        <->Text',\n",
       " '}<->Punctuation',\n",
       " '\\n<->Text',\n",
       " '\\n<->Text',\n",
       " '    <->Text',\n",
       " '}<->Punctuation',\n",
       " '\\n<->Text',\n",
       " '\\n<->Text',\n",
       " '\\n<->Text',\n",
       " '\\n<->Text',\n",
       " '    <->Text',\n",
       " 'public<->Keyword',\n",
       " ' <->Text',\n",
       " 'static<->Keyword',\n",
       " ' <->Text',\n",
       " 'void<->Keyword',\n",
       " ' <->Text',\n",
       " 'allDivisors<->Name',\n",
       " '(<->Punctuation',\n",
       " 'int<->Keyword',\n",
       " ' <->Text',\n",
       " 'n<->Name',\n",
       " ')<->Punctuation',\n",
       " ' <->Text',\n",
       " '{<->Punctuation',\n",
       " '\\n<->Text',\n",
       " '\\n<->Text',\n",
       " '        <->Text',\n",
       " 'for<->Keyword',\n",
       " '(<->Punctuation',\n",
       " 'int<->Keyword',\n",
       " ' <->Text',\n",
       " 'i<->Name',\n",
       " ' <->Text',\n",
       " '=<->Operator',\n",
       " ' <->Text',\n",
       " '1<->Literal',\n",
       " ';<->Punctuation',\n",
       " ' <->Text',\n",
       " 'i<->Name',\n",
       " '*<->Operator',\n",
       " 'i<->Name',\n",
       " ' <->Text',\n",
       " '<<->Operator',\n",
       " '=<->Operator',\n",
       " ' <->Text',\n",
       " 'n<->Name',\n",
       " ';<->Punctuation',\n",
       " ' <->Text',\n",
       " 'i<->Name',\n",
       " '+<->Operator',\n",
       " '+<->Operator',\n",
       " ')<->Punctuation',\n",
       " ' <->Text',\n",
       " '{<->Punctuation',\n",
       " '\\n<->Text',\n",
       " '\\n<->Text',\n",
       " '            <->Text',\n",
       " 'if<->Keyword',\n",
       " '(<->Punctuation',\n",
       " 'n<->Name',\n",
       " '%<->Operator',\n",
       " 'i<->Name',\n",
       " ' <->Text',\n",
       " '=<->Operator',\n",
       " '=<->Operator',\n",
       " ' <->Text',\n",
       " '0<->Literal',\n",
       " ')<->Punctuation',\n",
       " ' <->Text',\n",
       " '{<->Punctuation',\n",
       " '\\n<->Text',\n",
       " '\\n<->Text',\n",
       " '                <->Text',\n",
       " 'System<->Name',\n",
       " '.<->Punctuation',\n",
       " 'out<->Name',\n",
       " '.<->Punctuation',\n",
       " 'println<->Name',\n",
       " '(<->Punctuation',\n",
       " 'i<->Name',\n",
       " ' <->Text',\n",
       " '+<->Operator',\n",
       " ' <->Text',\n",
       " '\"<->Literal',\n",
       " ' <->Literal',\n",
       " '\"<->Literal',\n",
       " ')<->Punctuation',\n",
       " ';<->Punctuation',\n",
       " '\\n<->Text',\n",
       " '\\n<->Text',\n",
       " '                <->Text',\n",
       " 'if<->Keyword',\n",
       " '(<->Punctuation',\n",
       " 'i<->Name',\n",
       " ' <->Text',\n",
       " '!<->Operator',\n",
       " '=<->Operator',\n",
       " ' <->Text',\n",
       " 'n<->Name',\n",
       " '/<->Operator',\n",
       " 'i<->Name',\n",
       " ')<->Punctuation',\n",
       " ' <->Text',\n",
       " '{<->Punctuation',\n",
       " '\\n<->Text',\n",
       " '\\n<->Text',\n",
       " '                    <->Text',\n",
       " 'System<->Name',\n",
       " '.<->Punctuation',\n",
       " 'out<->Name',\n",
       " '.<->Punctuation',\n",
       " 'println<->Name',\n",
       " '(<->Punctuation',\n",
       " 'n<->Name',\n",
       " '/<->Operator',\n",
       " 'i<->Name',\n",
       " ' <->Text',\n",
       " '+<->Operator',\n",
       " ' <->Text',\n",
       " '\"<->Literal',\n",
       " ' <->Literal',\n",
       " '\"<->Literal',\n",
       " ')<->Punctuation',\n",
       " ';<->Punctuation',\n",
       " '\\n<->Text',\n",
       " '\\n<->Text',\n",
       " '                <->Text',\n",
       " '}<->Punctuation',\n",
       " '\\n<->Text',\n",
       " '\\n<->Text',\n",
       " '            <->Text',\n",
       " '}<->Punctuation',\n",
       " '\\n<->Text',\n",
       " '\\n<->Text',\n",
       " '        <->Text',\n",
       " '}<->Punctuation',\n",
       " '\\n<->Text',\n",
       " '\\n<->Text',\n",
       " '    <->Text',\n",
       " '}<->Punctuation',\n",
       " '\\n<->Text',\n",
       " '\\n<->Text',\n",
       " '\\n<->Text',\n",
       " '\\n<->Text',\n",
       " '    <->Text',\n",
       " 'public<->Keyword',\n",
       " ' <->Text',\n",
       " 'static<->Keyword',\n",
       " ' <->Text',\n",
       " 'boolean<->Keyword',\n",
       " ' <->Text',\n",
       " 'isPrime<->Name',\n",
       " '(<->Punctuation',\n",
       " 'int<->Keyword',\n",
       " ' <->Text',\n",
       " 'n<->Name',\n",
       " ')<->Punctuation',\n",
       " ' <->Text',\n",
       " '{<->Punctuation',\n",
       " '\\n<->Text',\n",
       " '\\n<->Text',\n",
       " '        <->Text',\n",
       " 'if<->Keyword',\n",
       " '(<->Punctuation',\n",
       " 'n<->Name',\n",
       " ' <->Text',\n",
       " '<<->Operator',\n",
       " ' <->Text',\n",
       " '1<->Literal',\n",
       " ')<->Punctuation',\n",
       " ' <->Text',\n",
       " 'return<->Keyword',\n",
       " ' <->Text',\n",
       " 'false<->Keyword',\n",
       " ';<->Punctuation',\n",
       " '\\n<->Text',\n",
       " '\\n<->Text',\n",
       " '        <->Text',\n",
       " 'if<->Keyword',\n",
       " '(<->Punctuation',\n",
       " 'n<->Name',\n",
       " ' <->Text',\n",
       " '=<->Operator',\n",
       " '=<->Operator',\n",
       " ' <->Text',\n",
       " '2<->Literal',\n",
       " ' <->Text',\n",
       " '|<->Operator',\n",
       " '|<->Operator',\n",
       " ' <->Text',\n",
       " 'n<->Name',\n",
       " ' <->Text',\n",
       " '=<->Operator',\n",
       " '=<->Operator',\n",
       " ' <->Text',\n",
       " '3<->Literal',\n",
       " ')<->Punctuation',\n",
       " ' <->Text',\n",
       " 'return<->Keyword',\n",
       " ' <->Text',\n",
       " 'true<->Keyword',\n",
       " ';<->Punctuation',\n",
       " '\\n<->Text',\n",
       " '\\n<->Text',\n",
       " '        <->Text',\n",
       " 'if<->Keyword',\n",
       " '(<->Punctuation',\n",
       " 'n<->Name',\n",
       " ' <->Text',\n",
       " '%<->Operator',\n",
       " ' <->Text',\n",
       " '2<->Literal',\n",
       " ' <->Text',\n",
       " '=<->Operator',\n",
       " '=<->Operator',\n",
       " ' <->Text',\n",
       " '0<->Literal',\n",
       " ' <->Text',\n",
       " '|<->Operator',\n",
       " '|<->Operator',\n",
       " ' <->Text',\n",
       " 'n<->Name',\n",
       " ' <->Text',\n",
       " '%<->Operator',\n",
       " ' <->Text',\n",
       " '3<->Literal',\n",
       " ' <->Text',\n",
       " '=<->Operator',\n",
       " '=<->Operator',\n",
       " ' <->Text',\n",
       " '0<->Literal',\n",
       " ')<->Punctuation',\n",
       " ' <->Text',\n",
       " 'return<->Keyword',\n",
       " ' <->Text',\n",
       " 'false<->Keyword',\n",
       " ';<->Punctuation',\n",
       " '\\n<->Text',\n",
       " '\\n<->Text',\n",
       " '        <->Text',\n",
       " 'for<->Keyword',\n",
       " '(<->Punctuation',\n",
       " 'int<->Keyword',\n",
       " ' <->Text',\n",
       " 'i<->Name',\n",
       " ' <->Text',\n",
       " '=<->Operator',\n",
       " ' <->Text',\n",
       " '5<->Literal',\n",
       " ';<->Punctuation',\n",
       " ' <->Text',\n",
       " 'i<->Name',\n",
       " '*<->Operator',\n",
       " 'i<->Name',\n",
       " ' <->Text',\n",
       " '<<->Operator',\n",
       " '=<->Operator',\n",
       " ' <->Text',\n",
       " 'n<->Name',\n",
       " ';<->Punctuation',\n",
       " ' <->Text',\n",
       " 'i<->Name',\n",
       " ' <->Text',\n",
       " '+<->Operator',\n",
       " '=<->Operator',\n",
       " ' <->Text',\n",
       " '6<->Literal',\n",
       " ')<->Punctuation',\n",
       " ' <->Text',\n",
       " '{<->Punctuation',\n",
       " '\\n<->Text',\n",
       " '\\n<->Text',\n",
       " '            <->Text',\n",
       " 'if<->Keyword',\n",
       " '(<->Punctuation',\n",
       " 'n<->Name',\n",
       " ' <->Text',\n",
       " '%<->Operator',\n",
       " ' <->Text',\n",
       " 'i<->Name',\n",
       " ' <->Text',\n",
       " '=<->Operator',\n",
       " '=<->Operator',\n",
       " ' <->Text',\n",
       " '0<->Literal',\n",
       " ' <->Text',\n",
       " '|<->Operator',\n",
       " '|<->Operator',\n",
       " ' <->Text',\n",
       " 'n<->Name',\n",
       " ' <->Text',\n",
       " '%<->Operator',\n",
       " ' <->Text',\n",
       " '(<->Punctuation',\n",
       " 'i<->Name',\n",
       " '+<->Operator',\n",
       " '2<->Literal',\n",
       " ')<->Punctuation',\n",
       " ' <->Text',\n",
       " '=<->Operator',\n",
       " '=<->Operator',\n",
       " ' <->Text',\n",
       " '0<->Literal',\n",
       " ')<->Punctuation',\n",
       " ' <->Text',\n",
       " '{<->Punctuation',\n",
       " '\\n<->Text',\n",
       " '\\n<->Text',\n",
       " '                <->Text',\n",
       " 'return<->Keyword',\n",
       " ' <->Text',\n",
       " 'false<->Keyword',\n",
       " ';<->Punctuation',\n",
       " '\\n<->Text',\n",
       " '\\n<->Text',\n",
       " '            <->Text',\n",
       " '}<->Punctuation',\n",
       " '\\n<->Text',\n",
       " '\\n<->Text',\n",
       " '        <->Text',\n",
       " '}<->Punctuation',\n",
       " '\\n<->Text',\n",
       " '\\n<->Text',\n",
       " '        <->Text',\n",
       " 'return<->Keyword',\n",
       " ' <->Text',\n",
       " 'true<->Keyword',\n",
       " ';<->Punctuation',\n",
       " '\\n<->Text',\n",
       " '\\n<->Text',\n",
       " '    <->Text',\n",
       " '}<->Punctuation',\n",
       " '\\n<->Text',\n",
       " '\\n<->Text',\n",
       " '\\n<->Text',\n",
       " '\\n<->Text',\n",
       " '    <->Text',\n",
       " 'public<->Keyword',\n",
       " ' <->Text',\n",
       " 'static<->Keyword',\n",
       " ' <->Text',\n",
       " 'int<->Keyword',\n",
       " ' <->Text',\n",
       " 'gcd<->Name',\n",
       " '(<->Punctuation',\n",
       " 'int<->Keyword',\n",
       " ' <->Text',\n",
       " 'a<->Name',\n",
       " ',<->Punctuation',\n",
       " ' <->Text',\n",
       " 'int<->Keyword',\n",
       " ' <->Text',\n",
       " 'b<->Name',\n",
       " ')<->Punctuation',\n",
       " ' <->Text',\n",
       " '{<->Punctuation',\n",
       " '\\n<->Text',\n",
       " '\\n<->Text',\n",
       " '        <->Text',\n",
       " 'int<->Keyword',\n",
       " ' <->Text',\n",
       " 'dividend<->Name',\n",
       " ' <->Text',\n",
       " '=<->Operator',\n",
       " ' <->Text',\n",
       " 'a<->Name',\n",
       " ' <->Text',\n",
       " '><->Operator',\n",
       " ' <->Text',\n",
       " 'b<->Name',\n",
       " ' <->Text',\n",
       " '?<->Operator',\n",
       " ' <->Text',\n",
       " 'a<->Name',\n",
       " ' <->Text',\n",
       " ':<->Punctuation',\n",
       " ' <->Text',\n",
       " 'b<->Name',\n",
       " ';<->Punctuation',\n",
       " '\\n<->Text',\n",
       " '\\n<->Text',\n",
       " '        <->Text',\n",
       " 'int<->Keyword',\n",
       " ' <->Text',\n",
       " 'divisor<->Name',\n",
       " ' <->Text',\n",
       " '=<->Operator',\n",
       " '  <->Text',\n",
       " 'a<->Name',\n",
       " ' <->Text',\n",
       " '<<->Operator',\n",
       " ' <->Text',\n",
       " 'b<->Name',\n",
       " ' <->Text',\n",
       " '?<->Operator',\n",
       " ' <->Text',\n",
       " 'a<->Name',\n",
       " ' <->Text',\n",
       " ':<->Punctuation',\n",
       " ' <->Text',\n",
       " 'b<->Name',\n",
       " ';<->Punctuation',\n",
       " '\\n<->Text',\n",
       " '\\n<->Text',\n",
       " '        <->Text',\n",
       " '\\n<->Text',\n",
       " '\\n<->Text',\n",
       " '        <->Text',\n",
       " 'while<->Keyword',\n",
       " '(<->Punctuation',\n",
       " 'divisor<->Name',\n",
       " ' <->Text',\n",
       " '><->Operator',\n",
       " ' <->Text',\n",
       " '0<->Literal',\n",
       " ')<->Punctuation',\n",
       " ' <->Text',\n",
       " '{<->Punctuation',\n",
       " '\\n<->Text',\n",
       " '\\n<->Text',\n",
       " '            <->Text',\n",
       " 'int<->Keyword',\n",
       " ' <->Text',\n",
       " 'reminder<->Name',\n",
       " ' <->Text',\n",
       " '=<->Operator',\n",
       " ' <->Text',\n",
       " 'dividend<->Name',\n",
       " ' <->Text',\n",
       " '%<->Operator',\n",
       " ' <->Text',\n",
       " 'divisor<->Name',\n",
       " ';<->Punctuation',\n",
       " '\\n<->Text',\n",
       " '\\n<->Text',\n",
       " '            <->Text',\n",
       " 'dividend<->Name',\n",
       " ' <->Text',\n",
       " '=<->Operator',\n",
       " ' <->Text',\n",
       " 'divisor<->Name',\n",
       " ';<->Punctuation',\n",
       " '\\n<->Text',\n",
       " '\\n<->Text',\n",
       " '            <->Text',\n",
       " 'divisor<->Name',\n",
       " ' <->Text',\n",
       " '=<->Operator',\n",
       " ' <->Text',\n",
       " 'reminder<->Name',\n",
       " ';<->Punctuation',\n",
       " '\\n<->Text',\n",
       " '\\n<->Text',\n",
       " '        <->Text',\n",
       " '}<->Punctuation',\n",
       " '\\n<->Text',\n",
       " '\\n<->Text',\n",
       " '        <->Text',\n",
       " 'return<->Keyword',\n",
       " ' <->Text',\n",
       " 'dividend<->Name',\n",
       " ';<->Punctuation',\n",
       " '\\n<->Text',\n",
       " '\\n<->Text',\n",
       " '    <->Text',\n",
       " '}<->Punctuation',\n",
       " '\\n<->Text',\n",
       " '\\n<->Text',\n",
       " '\\n<->Text',\n",
       " '\\n<->Text',\n",
       " '    <->Text',\n",
       " 'public<->Keyword',\n",
       " ' <->Text',\n",
       " 'static<->Keyword',\n",
       " ' <->Text',\n",
       " 'int<->Keyword',\n",
       " ' <->Text',\n",
       " 'lcm<->Name',\n",
       " '(<->Punctuation',\n",
       " 'int<->Keyword',\n",
       " ' <->Text',\n",
       " 'a<->Name',\n",
       " ',<->Punctuation',\n",
       " ' <->Text',\n",
       " 'int<->Keyword',\n",
       " ' <->Text',\n",
       " 'b<->Name',\n",
       " ')<->Punctuation',\n",
       " ' <->Text',\n",
       " '{<->Punctuation',\n",
       " '\\n<->Text',\n",
       " '\\n<->Text',\n",
       " '        <->Text',\n",
       " 'int<->Keyword',\n",
       " ' <->Text',\n",
       " 'lcm<->Name',\n",
       " ' <->Text',\n",
       " '=<->Operator',\n",
       " ' <->Text',\n",
       " 'gcd<->Name',\n",
       " '(<->Punctuation',\n",
       " 'a<->Name',\n",
       " ',<->Punctuation',\n",
       " ' <->Text',\n",
       " 'b<->Name',\n",
       " ')<->Punctuation',\n",
       " ';<->Punctuation',\n",
       " ...]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flatten_list(D_tr[\"text_base\"].to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3247cd88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build pLID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc81d7f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "258ba48d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code</th>\n",
       "      <th>generator</th>\n",
       "      <th>label</th>\n",
       "      <th>language</th>\n",
       "      <th>token_obj</th>\n",
       "      <th>tokens</th>\n",
       "      <th>base_type</th>\n",
       "      <th>text</th>\n",
       "      <th>base</th>\n",
       "      <th>text_base</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>361965</th>\n",
       "      <td>t = int(input())\\nfor _ in range(t):\\n\\tk = [l...</td>\n",
       "      <td>human</td>\n",
       "      <td>0</td>\n",
       "      <td>Python</td>\n",
       "      <td>{'language': 'Python', 'tokens': [{'text': 't'...</td>\n",
       "      <td>[{'text': 't', 'type': 'Token.Name', 'base_typ...</td>\n",
       "      <td>[Name, Text, Operator, Text, Name, Punctuation...</td>\n",
       "      <td>[t,  , =,  , int, (, input, (, ), ), \\n, for, ...</td>\n",
       "      <td>[Name, Text, Operator, Text, Name, Punctuation...</td>\n",
       "      <td>[t&lt;-&gt;Name,  &lt;-&gt;Text, =&lt;-&gt;Operator,  &lt;-&gt;Text, i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179837</th>\n",
       "      <td>import static java.lang.Math.max;\\n\\nimport st...</td>\n",
       "      <td>human</td>\n",
       "      <td>0</td>\n",
       "      <td>Java</td>\n",
       "      <td>{'language': 'Java', 'tokens': [{'text': 'impo...</td>\n",
       "      <td>[{'text': 'import static', 'type': 'Token.Keyw...</td>\n",
       "      <td>[Keyword, Text, Name, Punctuation, Text, Text,...</td>\n",
       "      <td>[import static,  , java.lang.Math.max, ;, \\n, ...</td>\n",
       "      <td>[Keyword, Text, Name, Punctuation, Text, Text,...</td>\n",
       "      <td>[import static&lt;-&gt;Keyword,  &lt;-&gt;Text, java.lang....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>472639</th>\n",
       "      <td>(n, *a) = map(int, open(0).read().split())\\nm ...</td>\n",
       "      <td>human</td>\n",
       "      <td>0</td>\n",
       "      <td>Python</td>\n",
       "      <td>{'language': 'Python', 'tokens': [{'text': '('...</td>\n",
       "      <td>[{'text': '(', 'type': 'Token.Punctuation', 'b...</td>\n",
       "      <td>[Punctuation, Name, Punctuation, Text, Operato...</td>\n",
       "      <td>[(, n, ,,  , *, a, ),  , =,  , map, (, int, ,,...</td>\n",
       "      <td>[Punctuation, Name, Punctuation, Text, Operato...</td>\n",
       "      <td>[(&lt;-&gt;Punctuation, n&lt;-&gt;Name, ,&lt;-&gt;Punctuation,  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97298</th>\n",
       "      <td>from collections import defaultdict\\n\\ndef are...</td>\n",
       "      <td>human</td>\n",
       "      <td>0</td>\n",
       "      <td>Python</td>\n",
       "      <td>{'language': 'Python', 'tokens': [{'text': 'fr...</td>\n",
       "      <td>[{'text': 'from', 'type': 'Token.Keyword.Names...</td>\n",
       "      <td>[Keyword, Text, Name, Text, Keyword, Text, Nam...</td>\n",
       "      <td>[from,  , collections,  , import,  , defaultdi...</td>\n",
       "      <td>[Keyword, Text, Name, Text, Keyword, Text, Nam...</td>\n",
       "      <td>[from&lt;-&gt;Keyword,  &lt;-&gt;Text, collections&lt;-&gt;Name,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276933</th>\n",
       "      <td>n = int(input())\\n(v, a) = ([0] * n, [0] * n)\\...</td>\n",
       "      <td>human</td>\n",
       "      <td>0</td>\n",
       "      <td>Python</td>\n",
       "      <td>{'language': 'Python', 'tokens': [{'text': 'n'...</td>\n",
       "      <td>[{'text': 'n', 'type': 'Token.Name', 'base_typ...</td>\n",
       "      <td>[Name, Text, Operator, Text, Name, Punctuation...</td>\n",
       "      <td>[n,  , =,  , int, (, input, (, ), ), \\n, (, v,...</td>\n",
       "      <td>[Name, Text, Operator, Text, Name, Punctuation...</td>\n",
       "      <td>[n&lt;-&gt;Name,  &lt;-&gt;Text, =&lt;-&gt;Operator,  &lt;-&gt;Text, i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>448969</th>\n",
       "      <td>bisect.bisect_left can be helpful in finding v...</td>\n",
       "      <td>microsoft/phi-2</td>\n",
       "      <td>1</td>\n",
       "      <td>Python</td>\n",
       "      <td>{'language': 'Python', 'tokens': [{'text': 'bi...</td>\n",
       "      <td>[{'text': 'bisect', 'type': 'Token.Name', 'bas...</td>\n",
       "      <td>[Name, Operator, Name, Text, Name, Text, Name,...</td>\n",
       "      <td>[bisect, ., bisect_left,  , can,  , be,  , hel...</td>\n",
       "      <td>[Name, Operator, Name, Text, Name, Text, Name,...</td>\n",
       "      <td>[bisect&lt;-&gt;Name, .&lt;-&gt;Operator, bisect_left&lt;-&gt;Na...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416400</th>\n",
       "      <td>, don't print anything.\\ndef beautiful_string_...</td>\n",
       "      <td>Qwen/Qwen2.5-Coder-1.5B</td>\n",
       "      <td>1</td>\n",
       "      <td>Python</td>\n",
       "      <td>{'language': 'Python', 'tokens': [{'text': ','...</td>\n",
       "      <td>[{'text': ',', 'type': 'Token.Punctuation', 'b...</td>\n",
       "      <td>[Punctuation, Text, Name, Literal, Literal, Te...</td>\n",
       "      <td>[,,  , don, ', t print anything., \\n, def,  , ...</td>\n",
       "      <td>[Punctuation, Text, Name, Literal, Literal, Te...</td>\n",
       "      <td>[,&lt;-&gt;Punctuation,  &lt;-&gt;Text, don&lt;-&gt;Name, '&lt;-&gt;Li...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61662</th>\n",
       "      <td>const int MAXN = 300005;\\n\\nnamespace Trie {\\n...</td>\n",
       "      <td>human</td>\n",
       "      <td>0</td>\n",
       "      <td>C++</td>\n",
       "      <td>{'language': 'C++', 'tokens': [{'text': 'const...</td>\n",
       "      <td>[{'text': 'const', 'type': 'Token.Keyword', 'b...</td>\n",
       "      <td>[Keyword, Text, Keyword, Text, Name, Text, Ope...</td>\n",
       "      <td>[const,  , int,  , MAXN,  , =,  , 300005, ;, \\...</td>\n",
       "      <td>[Keyword, Text, Keyword, Text, Name, Text, Ope...</td>\n",
       "      <td>[const&lt;-&gt;Keyword,  &lt;-&gt;Text, int&lt;-&gt;Keyword,  &lt;-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337637</th>\n",
       "      <td>python\\n\\ndef min_rectangle_cover(points):\\n  ...</td>\n",
       "      <td>01-ai/Yi-Coder-9B-Chat</td>\n",
       "      <td>1</td>\n",
       "      <td>Python</td>\n",
       "      <td>{'language': 'Python', 'tokens': [{'text': 'py...</td>\n",
       "      <td>[{'text': 'python', 'type': 'Token.Name', 'bas...</td>\n",
       "      <td>[Name, Text, Text, Keyword, Text, Name, Punctu...</td>\n",
       "      <td>[python, \\n, \\n, def,  , min_rectangle_cover, ...</td>\n",
       "      <td>[Name, Text, Text, Keyword, Text, Name, Punctu...</td>\n",
       "      <td>[python&lt;-&gt;Name, \\n&lt;-&gt;Text, \\n&lt;-&gt;Text, def&lt;-&gt;Ke...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72972</th>\n",
       "      <td>for _ in range(int(input())):\\n\\ts = input()\\n...</td>\n",
       "      <td>human</td>\n",
       "      <td>0</td>\n",
       "      <td>Python</td>\n",
       "      <td>{'language': 'Python', 'tokens': [{'text': 'fo...</td>\n",
       "      <td>[{'text': 'for', 'type': 'Token.Keyword', 'bas...</td>\n",
       "      <td>[Keyword, Text, Name, Text, Operator, Text, Na...</td>\n",
       "      <td>[for,  , _,  , in,  , range, (, int, (, input,...</td>\n",
       "      <td>[Keyword, Text, Name, Text, Operator, Text, Na...</td>\n",
       "      <td>[for&lt;-&gt;Keyword,  &lt;-&gt;Text, _&lt;-&gt;Name,  &lt;-&gt;Text, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     code  \\\n",
       "361965  t = int(input())\\nfor _ in range(t):\\n\\tk = [l...   \n",
       "179837  import static java.lang.Math.max;\\n\\nimport st...   \n",
       "472639  (n, *a) = map(int, open(0).read().split())\\nm ...   \n",
       "97298   from collections import defaultdict\\n\\ndef are...   \n",
       "276933  n = int(input())\\n(v, a) = ([0] * n, [0] * n)\\...   \n",
       "...                                                   ...   \n",
       "448969  bisect.bisect_left can be helpful in finding v...   \n",
       "416400  , don't print anything.\\ndef beautiful_string_...   \n",
       "61662   const int MAXN = 300005;\\n\\nnamespace Trie {\\n...   \n",
       "337637  python\\n\\ndef min_rectangle_cover(points):\\n  ...   \n",
       "72972   for _ in range(int(input())):\\n\\ts = input()\\n...   \n",
       "\n",
       "                      generator  label language  \\\n",
       "361965                    human      0   Python   \n",
       "179837                    human      0     Java   \n",
       "472639                    human      0   Python   \n",
       "97298                     human      0   Python   \n",
       "276933                    human      0   Python   \n",
       "...                         ...    ...      ...   \n",
       "448969          microsoft/phi-2      1   Python   \n",
       "416400  Qwen/Qwen2.5-Coder-1.5B      1   Python   \n",
       "61662                     human      0      C++   \n",
       "337637   01-ai/Yi-Coder-9B-Chat      1   Python   \n",
       "72972                     human      0   Python   \n",
       "\n",
       "                                                token_obj  \\\n",
       "361965  {'language': 'Python', 'tokens': [{'text': 't'...   \n",
       "179837  {'language': 'Java', 'tokens': [{'text': 'impo...   \n",
       "472639  {'language': 'Python', 'tokens': [{'text': '('...   \n",
       "97298   {'language': 'Python', 'tokens': [{'text': 'fr...   \n",
       "276933  {'language': 'Python', 'tokens': [{'text': 'n'...   \n",
       "...                                                   ...   \n",
       "448969  {'language': 'Python', 'tokens': [{'text': 'bi...   \n",
       "416400  {'language': 'Python', 'tokens': [{'text': ','...   \n",
       "61662   {'language': 'C++', 'tokens': [{'text': 'const...   \n",
       "337637  {'language': 'Python', 'tokens': [{'text': 'py...   \n",
       "72972   {'language': 'Python', 'tokens': [{'text': 'fo...   \n",
       "\n",
       "                                                   tokens  \\\n",
       "361965  [{'text': 't', 'type': 'Token.Name', 'base_typ...   \n",
       "179837  [{'text': 'import static', 'type': 'Token.Keyw...   \n",
       "472639  [{'text': '(', 'type': 'Token.Punctuation', 'b...   \n",
       "97298   [{'text': 'from', 'type': 'Token.Keyword.Names...   \n",
       "276933  [{'text': 'n', 'type': 'Token.Name', 'base_typ...   \n",
       "...                                                   ...   \n",
       "448969  [{'text': 'bisect', 'type': 'Token.Name', 'bas...   \n",
       "416400  [{'text': ',', 'type': 'Token.Punctuation', 'b...   \n",
       "61662   [{'text': 'const', 'type': 'Token.Keyword', 'b...   \n",
       "337637  [{'text': 'python', 'type': 'Token.Name', 'bas...   \n",
       "72972   [{'text': 'for', 'type': 'Token.Keyword', 'bas...   \n",
       "\n",
       "                                                base_type  \\\n",
       "361965  [Name, Text, Operator, Text, Name, Punctuation...   \n",
       "179837  [Keyword, Text, Name, Punctuation, Text, Text,...   \n",
       "472639  [Punctuation, Name, Punctuation, Text, Operato...   \n",
       "97298   [Keyword, Text, Name, Text, Keyword, Text, Nam...   \n",
       "276933  [Name, Text, Operator, Text, Name, Punctuation...   \n",
       "...                                                   ...   \n",
       "448969  [Name, Operator, Name, Text, Name, Text, Name,...   \n",
       "416400  [Punctuation, Text, Name, Literal, Literal, Te...   \n",
       "61662   [Keyword, Text, Keyword, Text, Name, Text, Ope...   \n",
       "337637  [Name, Text, Text, Keyword, Text, Name, Punctu...   \n",
       "72972   [Keyword, Text, Name, Text, Operator, Text, Na...   \n",
       "\n",
       "                                                     text  \\\n",
       "361965  [t,  , =,  , int, (, input, (, ), ), \\n, for, ...   \n",
       "179837  [import static,  , java.lang.Math.max, ;, \\n, ...   \n",
       "472639  [(, n, ,,  , *, a, ),  , =,  , map, (, int, ,,...   \n",
       "97298   [from,  , collections,  , import,  , defaultdi...   \n",
       "276933  [n,  , =,  , int, (, input, (, ), ), \\n, (, v,...   \n",
       "...                                                   ...   \n",
       "448969  [bisect, ., bisect_left,  , can,  , be,  , hel...   \n",
       "416400  [,,  , don, ', t print anything., \\n, def,  , ...   \n",
       "61662   [const,  , int,  , MAXN,  , =,  , 300005, ;, \\...   \n",
       "337637  [python, \\n, \\n, def,  , min_rectangle_cover, ...   \n",
       "72972   [for,  , _,  , in,  , range, (, int, (, input,...   \n",
       "\n",
       "                                                     base  \\\n",
       "361965  [Name, Text, Operator, Text, Name, Punctuation...   \n",
       "179837  [Keyword, Text, Name, Punctuation, Text, Text,...   \n",
       "472639  [Punctuation, Name, Punctuation, Text, Operato...   \n",
       "97298   [Keyword, Text, Name, Text, Keyword, Text, Nam...   \n",
       "276933  [Name, Text, Operator, Text, Name, Punctuation...   \n",
       "...                                                   ...   \n",
       "448969  [Name, Operator, Name, Text, Name, Text, Name,...   \n",
       "416400  [Punctuation, Text, Name, Literal, Literal, Te...   \n",
       "61662   [Keyword, Text, Keyword, Text, Name, Text, Ope...   \n",
       "337637  [Name, Text, Text, Keyword, Text, Name, Punctu...   \n",
       "72972   [Keyword, Text, Name, Text, Operator, Text, Na...   \n",
       "\n",
       "                                                text_base  \n",
       "361965  [t<->Name,  <->Text, =<->Operator,  <->Text, i...  \n",
       "179837  [import static<->Keyword,  <->Text, java.lang....  \n",
       "472639  [(<->Punctuation, n<->Name, ,<->Punctuation,  ...  \n",
       "97298   [from<->Keyword,  <->Text, collections<->Name,...  \n",
       "276933  [n<->Name,  <->Text, =<->Operator,  <->Text, i...  \n",
       "...                                                   ...  \n",
       "448969  [bisect<->Name, .<->Operator, bisect_left<->Na...  \n",
       "416400  [,<->Punctuation,  <->Text, don<->Name, '<->Li...  \n",
       "61662   [const<->Keyword,  <->Text, int<->Keyword,  <-...  \n",
       "337637  [python<->Name, \\n<->Text, \\n<->Text, def<->Ke...  \n",
       "72972   [for<->Keyword,  <->Text, _<->Name,  <->Text, ...  \n",
       "\n",
       "[10000 rows x 10 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D_tr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8c789df7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'Text': 1285889,\n",
       "         'Name': 741223,\n",
       "         'Punctuation': 716371,\n",
       "         'Operator': 393538,\n",
       "         'Literal': 268842,\n",
       "         'Keyword': 139774,\n",
       "         'Comment': 24032,\n",
       "         'Error': 9882})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(flatten_list(D_tr[\"base_type\"].to_list()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3a1ef750",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'Text': 1276265,\n",
       "         'Name': 733407,\n",
       "         'Punctuation': 715175,\n",
       "         'Operator': 386844,\n",
       "         'Literal': 264753,\n",
       "         'Keyword': 137690,\n",
       "         'Comment': 22545,\n",
       "         'Error': 9876})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(flatten_list(D_ev[\"base_type\"].to_list()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eeaf331",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:31<00:00, 318.27it/s]\n",
      "100%|██████████| 1000/1000 [00:03<00:00, 307.83it/s]\n"
     ]
    }
   ],
   "source": [
    "# Predict language\n",
    "D_tr[\"language_pred\"] = [\n",
    "    lang_detector.identify_bytes(f\"{code}\".encode('utf-8')).output.label\n",
    "    for code in tqdm(D_tr[\"code\"], total=len(D_tr))\n",
    "]\n",
    "\n",
    "D_ev[\"language_pred\"] = [\n",
    "    lang_detector.identify_bytes(f\"{code}\".encode('utf-8')).output.label\n",
    "    for code in tqdm(D_ev[\"code\"], total=len(D_ev))\n",
    "]\n",
    "\n",
    "D_te[\"language_pred\"] = [\n",
    "    lang_detector.identify_bytes(f\"{code}\".encode('utf-8')).output.label\n",
    "    for code in tqdm(D_te[\"code\"], total=len(D_te))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7450eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "semeval2pygment_ids = {\n",
    "    \"C++\": \"cpp\",\n",
    "    \"Python\": \"python\",\n",
    "    \"Java\": \"java\",\n",
    "    \"Go\": \"go\",\n",
    "    \"PHP\": \"php\",\n",
    "    \"C#\": \"c#\",\n",
    "    \"C\": \"c\",\n",
    "    \"JS\": \"javascript\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3984a45d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e2cf3e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d47e85fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f1dc088",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a958dd6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:10<00:00, 913.01it/s]\n",
      "100%|██████████| 10000/10000 [00:11<00:00, 849.58it/s]\n",
      "100%|██████████| 1000/1000 [00:01<00:00, 849.96it/s]\n"
     ]
    }
   ],
   "source": [
    "# Tokenize code\n",
    "D_tr[\"token_obj\"] = [tokenize_code(code, language=lang) for code, lang in tqdm(zip(D_tr[\"code\"], D_tr[\"language\"]), total=len(D_tr))]\n",
    "D_tr[\"tokens\"] = [obj[\"tokens\"] for obj in D_tr[\"token_obj\"]]\n",
    "\n",
    "D_ev[\"token_obj\"] = [tokenize_code(code, possible_languages=semeval2pygment_ids.values()) for code, lang in tqdm(zip(D_ev[\"code\"], D_ev[\"language\"]), total=len(D_ev))]\n",
    "D_ev[\"tokens\"] = [obj[\"tokens\"] for obj in D_ev[\"token_obj\"]]\n",
    "\n",
    "D_te[\"token_obj\"] = [tokenize_code(code, possible_languages=semeval2pygment_ids.values()) for code, lang in tqdm(zip(D_te[\"code\"], D_te[\"language\"]), total=len(D_te))]\n",
    "D_te[\"tokens\"] = [obj[\"tokens\"] for obj in D_te[\"token_obj\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "26848779",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24602    python\n",
       "94229      java\n",
       "64802    python\n",
       "7583     python\n",
       "16997      java\n",
       "          ...  \n",
       "63690    python\n",
       "59449    python\n",
       "19887    python\n",
       "81512    python\n",
       "80226    python\n",
       "Name: language, Length: 10000, dtype: object"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D_ev[\"language\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a7302535",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24602       c++\n",
       "94229       c++\n",
       "64802       c++\n",
       "7583        c++\n",
       "16997    python\n",
       "          ...  \n",
       "63690    python\n",
       "59449       c++\n",
       "19887       c++\n",
       "81512    python\n",
       "80226       c++\n",
       "Name: token_obj, Length: 10000, dtype: object"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D_ev[\"token_obj\"].apply(lambda x: semeval2pygment_ids[x[\"language\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0f127b03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting magika\n",
      "  Downloading magika-1.0.1-py3-none-macosx_11_0_arm64.whl.metadata (10 kB)\n",
      "Requirement already satisfied: click>=8.1.7 in /Users/rendvvv/miniconda3/envs/lingu/lib/python3.12/site-packages (from magika) (8.3.1)\n",
      "Collecting onnxruntime>=1.17.0 (from magika)\n",
      "  Downloading onnxruntime-1.23.2-cp312-cp312-macosx_13_0_arm64.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: numpy>=1.26 in /Users/rendvvv/miniconda3/envs/lingu/lib/python3.12/site-packages (from magika) (1.26.4)\n",
      "Collecting python-dotenv>=1.0.1 (from magika)\n",
      "  Using cached python_dotenv-1.2.1-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting coloredlogs (from onnxruntime>=1.17.0->magika)\n",
      "  Using cached coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
      "Collecting flatbuffers (from onnxruntime>=1.17.0->magika)\n",
      "  Using cached flatbuffers-25.9.23-py2.py3-none-any.whl.metadata (875 bytes)\n",
      "Requirement already satisfied: packaging in /Users/rendvvv/miniconda3/envs/lingu/lib/python3.12/site-packages (from onnxruntime>=1.17.0->magika) (25.0)\n",
      "Requirement already satisfied: protobuf in /Users/rendvvv/miniconda3/envs/lingu/lib/python3.12/site-packages (from onnxruntime>=1.17.0->magika) (6.33.1)\n",
      "Requirement already satisfied: sympy in /Users/rendvvv/miniconda3/envs/lingu/lib/python3.12/site-packages (from onnxruntime>=1.17.0->magika) (1.14.0)\n",
      "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.17.0->magika)\n",
      "  Using cached humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/rendvvv/miniconda3/envs/lingu/lib/python3.12/site-packages (from sympy->onnxruntime>=1.17.0->magika) (1.3.0)\n",
      "Downloading magika-1.0.1-py3-none-macosx_11_0_arm64.whl (13.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.4/13.4 MB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading onnxruntime-1.23.2-cp312-cp312-macosx_13_0_arm64.whl (17.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.2/17.2 MB\u001b[0m \u001b[31m24.5 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached python_dotenv-1.2.1-py3-none-any.whl (21 kB)\n",
      "Using cached coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
      "Using cached humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
      "Using cached flatbuffers-25.9.23-py2.py3-none-any.whl (30 kB)\n",
      "Installing collected packages: flatbuffers, python-dotenv, humanfriendly, coloredlogs, onnxruntime, magika\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6/6\u001b[0m [magika]2m4/6\u001b[0m [onnxruntime]\n",
      "\u001b[1A\u001b[2KSuccessfully installed coloredlogs-15.0.1 flatbuffers-25.9.23 humanfriendly-10.0 magika-1.0.1 onnxruntime-1.23.2 python-dotenv-1.2.1\n"
     ]
    }
   ],
   "source": [
    "!pip install magika"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f8a2d33",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "759630f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "javascript\n"
     ]
    }
   ],
   "source": [
    "m = Magika()\n",
    "res = m.identify_bytes(b'function log(msg) {console.log(msg);}')\n",
    "print(res.output.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "51b6f6a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           c       0.00      0.00      0.00         0\n",
      "         c++       0.06      0.97      0.11       451\n",
      "        java       0.00      0.00      0.00       384\n",
      "         php       0.00      0.00      0.00         0\n",
      "      python       0.93      0.26      0.40      9165\n",
      "\n",
      "    accuracy                           0.28     10000\n",
      "   macro avg       0.20      0.24      0.10     10000\n",
      "weighted avg       0.86      0.28      0.37     10000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rendvvv/miniconda3/envs/lingu/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/Users/rendvvv/miniconda3/envs/lingu/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/Users/rendvvv/miniconda3/envs/lingu/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/Users/rendvvv/miniconda3/envs/lingu/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/Users/rendvvv/miniconda3/envs/lingu/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/Users/rendvvv/miniconda3/envs/lingu/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(D_ev[\"language\"], D_ev[\"token_obj\"].apply(lambda x: semeval2pygment_ids[x[\"language\"]])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7468fb1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'text': 'def', 'type': 'Token.Keyword', 'base_type': 'Keyword'},\n",
       " {'text': ' ', 'type': 'Token.Text.Whitespace', 'base_type': 'Text'},\n",
       " {'text': 'range_search', 'type': 'Token.Name.Function', 'base_type': 'Name'},\n",
       " {'text': '(', 'type': 'Token.Punctuation', 'base_type': 'Punctuation'},\n",
       " {'text': 'points', 'type': 'Token.Name', 'base_type': 'Name'},\n",
       " {'text': ',', 'type': 'Token.Punctuation', 'base_type': 'Punctuation'},\n",
       " {'text': ' ', 'type': 'Token.Text', 'base_type': 'Text'},\n",
       " {'text': 'queries', 'type': 'Token.Name', 'base_type': 'Name'},\n",
       " {'text': ')', 'type': 'Token.Punctuation', 'base_type': 'Punctuation'},\n",
       " {'text': ':', 'type': 'Token.Punctuation', 'base_type': 'Punctuation'},\n",
       " {'text': '\\n', 'type': 'Token.Text.Whitespace', 'base_type': 'Text'},\n",
       " {'text': '    ', 'type': 'Token.Text', 'base_type': 'Text'},\n",
       " {'text': 'results', 'type': 'Token.Name', 'base_type': 'Name'},\n",
       " {'text': ' ', 'type': 'Token.Text', 'base_type': 'Text'},\n",
       " {'text': '=', 'type': 'Token.Operator', 'base_type': 'Operator'},\n",
       " {'text': ' ', 'type': 'Token.Text', 'base_type': 'Text'},\n",
       " {'text': '[', 'type': 'Token.Punctuation', 'base_type': 'Punctuation'},\n",
       " {'text': ']', 'type': 'Token.Punctuation', 'base_type': 'Punctuation'},\n",
       " {'text': '\\n', 'type': 'Token.Text.Whitespace', 'base_type': 'Text'},\n",
       " {'text': '    ', 'type': 'Token.Text', 'base_type': 'Text'},\n",
       " {'text': 'for', 'type': 'Token.Keyword', 'base_type': 'Keyword'},\n",
       " {'text': ' ', 'type': 'Token.Text', 'base_type': 'Text'},\n",
       " {'text': 'sx', 'type': 'Token.Name', 'base_type': 'Name'},\n",
       " {'text': ',', 'type': 'Token.Punctuation', 'base_type': 'Punctuation'},\n",
       " {'text': ' ', 'type': 'Token.Text', 'base_type': 'Text'},\n",
       " {'text': 'tx', 'type': 'Token.Name', 'base_type': 'Name'},\n",
       " {'text': ',', 'type': 'Token.Punctuation', 'base_type': 'Punctuation'},\n",
       " {'text': ' ', 'type': 'Token.Text', 'base_type': 'Text'},\n",
       " {'text': 'sy', 'type': 'Token.Name', 'base_type': 'Name'},\n",
       " {'text': ',', 'type': 'Token.Punctuation', 'base_type': 'Punctuation'},\n",
       " {'text': ' ', 'type': 'Token.Text', 'base_type': 'Text'},\n",
       " {'text': 'ty', 'type': 'Token.Name', 'base_type': 'Name'},\n",
       " {'text': ' ', 'type': 'Token.Text', 'base_type': 'Text'},\n",
       " {'text': 'in', 'type': 'Token.Operator.Word', 'base_type': 'Operator'},\n",
       " {'text': ' ', 'type': 'Token.Text', 'base_type': 'Text'},\n",
       " {'text': 'queries', 'type': 'Token.Name', 'base_type': 'Name'},\n",
       " {'text': ':', 'type': 'Token.Punctuation', 'base_type': 'Punctuation'},\n",
       " {'text': '\\n', 'type': 'Token.Text.Whitespace', 'base_type': 'Text'},\n",
       " {'text': '        ', 'type': 'Token.Text', 'base_type': 'Text'},\n",
       " {'text': 'points_in_range', 'type': 'Token.Name', 'base_type': 'Name'},\n",
       " {'text': ' ', 'type': 'Token.Text', 'base_type': 'Text'},\n",
       " {'text': '=', 'type': 'Token.Operator', 'base_type': 'Operator'},\n",
       " {'text': ' ', 'type': 'Token.Text', 'base_type': 'Text'},\n",
       " {'text': '[', 'type': 'Token.Punctuation', 'base_type': 'Punctuation'},\n",
       " {'text': 'i', 'type': 'Token.Name', 'base_type': 'Name'},\n",
       " {'text': ' ', 'type': 'Token.Text', 'base_type': 'Text'},\n",
       " {'text': 'for', 'type': 'Token.Keyword', 'base_type': 'Keyword'},\n",
       " {'text': ' ', 'type': 'Token.Text', 'base_type': 'Text'},\n",
       " {'text': 'i', 'type': 'Token.Name', 'base_type': 'Name'},\n",
       " {'text': ',', 'type': 'Token.Punctuation', 'base_type': 'Punctuation'},\n",
       " {'text': ' ', 'type': 'Token.Text', 'base_type': 'Text'},\n",
       " {'text': '(', 'type': 'Token.Punctuation', 'base_type': 'Punctuation'},\n",
       " {'text': 'x', 'type': 'Token.Name', 'base_type': 'Name'},\n",
       " {'text': ',', 'type': 'Token.Punctuation', 'base_type': 'Punctuation'},\n",
       " {'text': ' ', 'type': 'Token.Text', 'base_type': 'Text'},\n",
       " {'text': 'y', 'type': 'Token.Name', 'base_type': 'Name'},\n",
       " {'text': ')', 'type': 'Token.Punctuation', 'base_type': 'Punctuation'},\n",
       " {'text': ' ', 'type': 'Token.Text', 'base_type': 'Text'},\n",
       " {'text': 'in', 'type': 'Token.Operator.Word', 'base_type': 'Operator'},\n",
       " {'text': ' ', 'type': 'Token.Text', 'base_type': 'Text'},\n",
       " {'text': 'enumerate', 'type': 'Token.Name.Builtin', 'base_type': 'Name'},\n",
       " {'text': '(', 'type': 'Token.Punctuation', 'base_type': 'Punctuation'},\n",
       " {'text': 'points', 'type': 'Token.Name', 'base_type': 'Name'},\n",
       " {'text': ')', 'type': 'Token.Punctuation', 'base_type': 'Punctuation'},\n",
       " {'text': ' ', 'type': 'Token.Text', 'base_type': 'Text'},\n",
       " {'text': 'if', 'type': 'Token.Keyword', 'base_type': 'Keyword'},\n",
       " {'text': ' ', 'type': 'Token.Text', 'base_type': 'Text'},\n",
       " {'text': 'sx', 'type': 'Token.Name', 'base_type': 'Name'},\n",
       " {'text': ' ', 'type': 'Token.Text', 'base_type': 'Text'},\n",
       " {'text': '<', 'type': 'Token.Operator', 'base_type': 'Operator'},\n",
       " {'text': '=', 'type': 'Token.Operator', 'base_type': 'Operator'},\n",
       " {'text': ' ', 'type': 'Token.Text', 'base_type': 'Text'},\n",
       " {'text': 'x', 'type': 'Token.Name', 'base_type': 'Name'},\n",
       " {'text': ' ', 'type': 'Token.Text', 'base_type': 'Text'},\n",
       " {'text': '<', 'type': 'Token.Operator', 'base_type': 'Operator'},\n",
       " {'text': '=', 'type': 'Token.Operator', 'base_type': 'Operator'},\n",
       " {'text': ' ', 'type': 'Token.Text', 'base_type': 'Text'},\n",
       " {'text': 'tx', 'type': 'Token.Name', 'base_type': 'Name'},\n",
       " {'text': ' ', 'type': 'Token.Text', 'base_type': 'Text'},\n",
       " {'text': 'and', 'type': 'Token.Operator.Word', 'base_type': 'Operator'},\n",
       " {'text': ' ', 'type': 'Token.Text', 'base_type': 'Text'},\n",
       " {'text': 'sy', 'type': 'Token.Name', 'base_type': 'Name'},\n",
       " {'text': ' ', 'type': 'Token.Text', 'base_type': 'Text'},\n",
       " {'text': '<', 'type': 'Token.Operator', 'base_type': 'Operator'},\n",
       " {'text': '=', 'type': 'Token.Operator', 'base_type': 'Operator'},\n",
       " {'text': ' ', 'type': 'Token.Text', 'base_type': 'Text'},\n",
       " {'text': 'y', 'type': 'Token.Name', 'base_type': 'Name'},\n",
       " {'text': ' ', 'type': 'Token.Text', 'base_type': 'Text'},\n",
       " {'text': '<', 'type': 'Token.Operator', 'base_type': 'Operator'},\n",
       " {'text': '=', 'type': 'Token.Operator', 'base_type': 'Operator'},\n",
       " {'text': ' ', 'type': 'Token.Text', 'base_type': 'Text'},\n",
       " {'text': 'ty', 'type': 'Token.Name', 'base_type': 'Name'},\n",
       " {'text': ']', 'type': 'Token.Punctuation', 'base_type': 'Punctuation'},\n",
       " {'text': '\\n', 'type': 'Token.Text.Whitespace', 'base_type': 'Text'},\n",
       " {'text': '        ', 'type': 'Token.Text', 'base_type': 'Text'},\n",
       " {'text': 'results', 'type': 'Token.Name', 'base_type': 'Name'},\n",
       " {'text': '.', 'type': 'Token.Operator', 'base_type': 'Operator'},\n",
       " {'text': 'append', 'type': 'Token.Name', 'base_type': 'Name'},\n",
       " {'text': '(', 'type': 'Token.Punctuation', 'base_type': 'Punctuation'},\n",
       " {'text': 'points_in_range', 'type': 'Token.Name', 'base_type': 'Name'},\n",
       " {'text': ')', 'type': 'Token.Punctuation', 'base_type': 'Punctuation'},\n",
       " {'text': '\\n', 'type': 'Token.Text.Whitespace', 'base_type': 'Text'},\n",
       " {'text': '    ', 'type': 'Token.Text', 'base_type': 'Text'},\n",
       " {'text': '\\n', 'type': 'Token.Text.Whitespace', 'base_type': 'Text'},\n",
       " {'text': '    ', 'type': 'Token.Text', 'base_type': 'Text'},\n",
       " {'text': 'for', 'type': 'Token.Keyword', 'base_type': 'Keyword'},\n",
       " {'text': ' ', 'type': 'Token.Text', 'base_type': 'Text'},\n",
       " {'text': 'result', 'type': 'Token.Name', 'base_type': 'Name'},\n",
       " {'text': ' ', 'type': 'Token.Text', 'base_type': 'Text'},\n",
       " {'text': 'in', 'type': 'Token.Operator.Word', 'base_type': 'Operator'},\n",
       " {'text': ' ', 'type': 'Token.Text', 'base_type': 'Text'},\n",
       " {'text': 'results', 'type': 'Token.Name', 'base_type': 'Name'},\n",
       " {'text': ':', 'type': 'Token.Punctuation', 'base_type': 'Punctuation'},\n",
       " {'text': '\\n', 'type': 'Token.Text.Whitespace', 'base_type': 'Text'},\n",
       " {'text': '        ', 'type': 'Token.Text', 'base_type': 'Text'},\n",
       " {'text': 'for', 'type': 'Token.Keyword', 'base_type': 'Keyword'},\n",
       " {'text': ' ', 'type': 'Token.Text', 'base_type': 'Text'},\n",
       " {'text': 'point_id', 'type': 'Token.Name', 'base_type': 'Name'},\n",
       " {'text': ' ', 'type': 'Token.Text', 'base_type': 'Text'},\n",
       " {'text': 'in', 'type': 'Token.Operator.Word', 'base_type': 'Operator'},\n",
       " {'text': ' ', 'type': 'Token.Text', 'base_type': 'Text'},\n",
       " {'text': 'result', 'type': 'Token.Name', 'base_type': 'Name'},\n",
       " {'text': ':', 'type': 'Token.Punctuation', 'base_type': 'Punctuation'},\n",
       " {'text': '\\n', 'type': 'Token.Text.Whitespace', 'base_type': 'Text'},\n",
       " {'text': '            ', 'type': 'Token.Text', 'base_type': 'Text'},\n",
       " {'text': 'print', 'type': 'Token.Name.Builtin', 'base_type': 'Name'},\n",
       " {'text': '(', 'type': 'Token.Punctuation', 'base_type': 'Punctuation'},\n",
       " {'text': 'point_id', 'type': 'Token.Name', 'base_type': 'Name'},\n",
       " {'text': ')', 'type': 'Token.Punctuation', 'base_type': 'Punctuation'},\n",
       " {'text': '\\n', 'type': 'Token.Text.Whitespace', 'base_type': 'Text'},\n",
       " {'text': '        ', 'type': 'Token.Text', 'base_type': 'Text'},\n",
       " {'text': 'print', 'type': 'Token.Name.Builtin', 'base_type': 'Name'},\n",
       " {'text': '(', 'type': 'Token.Punctuation', 'base_type': 'Punctuation'},\n",
       " {'text': ')', 'type': 'Token.Punctuation', 'base_type': 'Punctuation'},\n",
       " {'text': '\\n', 'type': 'Token.Text.Whitespace', 'base_type': 'Text'},\n",
       " {'text': '\\n', 'type': 'Token.Text.Whitespace', 'base_type': 'Text'},\n",
       " {'text': 'def', 'type': 'Token.Keyword', 'base_type': 'Keyword'},\n",
       " {'text': ' ', 'type': 'Token.Text.Whitespace', 'base_type': 'Text'},\n",
       " {'text': 'main', 'type': 'Token.Name.Function', 'base_type': 'Name'},\n",
       " {'text': '(', 'type': 'Token.Punctuation', 'base_type': 'Punctuation'},\n",
       " {'text': ')', 'type': 'Token.Punctuation', 'base_type': 'Punctuation'},\n",
       " {'text': ':', 'type': 'Token.Punctuation', 'base_type': 'Punctuation'},\n",
       " {'text': '\\n', 'type': 'Token.Text.Whitespace', 'base_type': 'Text'},\n",
       " {'text': '    ', 'type': 'Token.Text', 'base_type': 'Text'},\n",
       " {'text': 'import', 'type': 'Token.Keyword.Namespace', 'base_type': 'Keyword'},\n",
       " {'text': ' ', 'type': 'Token.Text.Whitespace', 'base_type': 'Text'},\n",
       " {'text': 'sys', 'type': 'Token.Name.Namespace', 'base_type': 'Name'},\n",
       " {'text': '\\n', 'type': 'Token.Text.Whitespace', 'base_type': 'Text'},\n",
       " {'text': '    ', 'type': 'Token.Text', 'base_type': 'Text'},\n",
       " {'text': 'input', 'type': 'Token.Name.Builtin', 'base_type': 'Name'},\n",
       " {'text': ' ', 'type': 'Token.Text', 'base_type': 'Text'},\n",
       " {'text': '=', 'type': 'Token.Operator', 'base_type': 'Operator'},\n",
       " {'text': ' ', 'type': 'Token.Text', 'base_type': 'Text'},\n",
       " {'text': 'sys', 'type': 'Token.Name', 'base_type': 'Name'},\n",
       " {'text': '.', 'type': 'Token.Operator', 'base_type': 'Operator'},\n",
       " {'text': 'stdin', 'type': 'Token.Name', 'base_type': 'Name'},\n",
       " {'text': '.', 'type': 'Token.Operator', 'base_type': 'Operator'},\n",
       " {'text': 'read', 'type': 'Token.Name', 'base_type': 'Name'},\n",
       " {'text': '\\n', 'type': 'Token.Text.Whitespace', 'base_type': 'Text'},\n",
       " {'text': '    ', 'type': 'Token.Text', 'base_type': 'Text'},\n",
       " {'text': 'data', 'type': 'Token.Name', 'base_type': 'Name'},\n",
       " {'text': ' ', 'type': 'Token.Text', 'base_type': 'Text'},\n",
       " {'text': '=', 'type': 'Token.Operator', 'base_type': 'Operator'},\n",
       " {'text': ' ', 'type': 'Token.Text', 'base_type': 'Text'},\n",
       " {'text': 'input', 'type': 'Token.Name.Builtin', 'base_type': 'Name'},\n",
       " {'text': '(', 'type': 'Token.Punctuation', 'base_type': 'Punctuation'},\n",
       " {'text': ')', 'type': 'Token.Punctuation', 'base_type': 'Punctuation'},\n",
       " {'text': '.', 'type': 'Token.Operator', 'base_type': 'Operator'},\n",
       " {'text': 'split', 'type': 'Token.Name', 'base_type': 'Name'},\n",
       " {'text': '(', 'type': 'Token.Punctuation', 'base_type': 'Punctuation'},\n",
       " {'text': ')', 'type': 'Token.Punctuation', 'base_type': 'Punctuation'},\n",
       " {'text': '\\n', 'type': 'Token.Text.Whitespace', 'base_type': 'Text'},\n",
       " {'text': '\\n', 'type': 'Token.Text.Whitespace', 'base_type': 'Text'},\n",
       " {'text': '    ', 'type': 'Token.Text', 'base_type': 'Text'},\n",
       " {'text': 'index', 'type': 'Token.Name', 'base_type': 'Name'},\n",
       " {'text': ' ', 'type': 'Token.Text', 'base_type': 'Text'},\n",
       " {'text': '=', 'type': 'Token.Operator', 'base_type': 'Operator'},\n",
       " {'text': ' ', 'type': 'Token.Text', 'base_type': 'Text'},\n",
       " {'text': '0', 'type': 'Token.Literal.Number.Integer', 'base_type': 'Literal'},\n",
       " {'text': '\\n', 'type': 'Token.Text.Whitespace', 'base_type': 'Text'},\n",
       " {'text': '    ', 'type': 'Token.Text', 'base_type': 'Text'},\n",
       " {'text': 'n', 'type': 'Token.Name', 'base_type': 'Name'},\n",
       " {'text': ' ', 'type': 'Token.Text', 'base_type': 'Text'},\n",
       " {'text': '=', 'type': 'Token.Operator', 'base_type': 'Operator'},\n",
       " {'text': ' ', 'type': 'Token.Text', 'base_type': 'Text'},\n",
       " {'text': 'int', 'type': 'Token.Name.Builtin', 'base_type': 'Name'},\n",
       " {'text': '(', 'type': 'Token.Punctuation', 'base_type': 'Punctuation'},\n",
       " {'text': 'data', 'type': 'Token.Name', 'base_type': 'Name'},\n",
       " {'text': '[', 'type': 'Token.Punctuation', 'base_type': 'Punctuation'},\n",
       " {'text': 'index', 'type': 'Token.Name', 'base_type': 'Name'},\n",
       " {'text': ']', 'type': 'Token.Punctuation', 'base_type': 'Punctuation'},\n",
       " {'text': ')', 'type': 'Token.Punctuation', 'base_type': 'Punctuation'},\n",
       " {'text': '\\n', 'type': 'Token.Text.Whitespace', 'base_type': 'Text'},\n",
       " {'text': '    ', 'type': 'Token.Text', 'base_type': 'Text'},\n",
       " {'text': 'index', 'type': 'Token.Name', 'base_type': 'Name'},\n",
       " {'text': ' ', 'type': 'Token.Text', 'base_type': 'Text'},\n",
       " {'text': '+', 'type': 'Token.Operator', 'base_type': 'Operator'},\n",
       " {'text': '=', 'type': 'Token.Operator', 'base_type': 'Operator'},\n",
       " {'text': ' ', 'type': 'Token.Text', 'base_type': 'Text'},\n",
       " {'text': '1', 'type': 'Token.Literal.Number.Integer', 'base_type': 'Literal'},\n",
       " {'text': '\\n', 'type': 'Token.Text.Whitespace', 'base_type': 'Text'},\n",
       " {'text': '    ', 'type': 'Token.Text', 'base_type': 'Text'},\n",
       " {'text': 'points', 'type': 'Token.Name', 'base_type': 'Name'},\n",
       " {'text': ' ', 'type': 'Token.Text', 'base_type': 'Text'},\n",
       " {'text': '=', 'type': 'Token.Operator', 'base_type': 'Operator'},\n",
       " {'text': ' ', 'type': 'Token.Text', 'base_type': 'Text'},\n",
       " {'text': '[', 'type': 'Token.Punctuation', 'base_type': 'Punctuation'},\n",
       " {'text': '(', 'type': 'Token.Punctuation', 'base_type': 'Punctuation'},\n",
       " {'text': 'int', 'type': 'Token.Name.Builtin', 'base_type': 'Name'},\n",
       " {'text': '(', 'type': 'Token.Punctuation', 'base_type': 'Punctuation'},\n",
       " {'text': 'data', 'type': 'Token.Name', 'base_type': 'Name'},\n",
       " {'text': '[', 'type': 'Token.Punctuation', 'base_type': 'Punctuation'},\n",
       " {'text': 'index', 'type': 'Token.Name', 'base_type': 'Name'},\n",
       " {'text': ']', 'type': 'Token.Punctuation', 'base_type': 'Punctuation'},\n",
       " {'text': ')', 'type': 'Token.Punctuation', 'base_type': 'Punctuation'},\n",
       " {'text': ',', 'type': 'Token.Punctuation', 'base_type': 'Punctuation'},\n",
       " {'text': ' ', 'type': 'Token.Text', 'base_type': 'Text'},\n",
       " {'text': 'int', 'type': 'Token.Name.Builtin', 'base_type': 'Name'},\n",
       " {'text': '(', 'type': 'Token.Punctuation', 'base_type': 'Punctuation'},\n",
       " {'text': 'data', 'type': 'Token.Name', 'base_type': 'Name'},\n",
       " {'text': '[', 'type': 'Token.Punctuation', 'base_type': 'Punctuation'},\n",
       " {'text': 'index', 'type': 'Token.Name', 'base_type': 'Name'},\n",
       " {'text': ' ', 'type': 'Token.Text', 'base_type': 'Text'},\n",
       " {'text': '+', 'type': 'Token.Operator', 'base_type': 'Operator'},\n",
       " {'text': ' ', 'type': 'Token.Text', 'base_type': 'Text'},\n",
       " {'text': '1', 'type': 'Token.Literal.Number.Integer', 'base_type': 'Literal'},\n",
       " {'text': ']', 'type': 'Token.Punctuation', 'base_type': 'Punctuation'},\n",
       " {'text': ')', 'type': 'Token.Punctuation', 'base_type': 'Punctuation'},\n",
       " {'text': ')', 'type': 'Token.Punctuation', 'base_type': 'Punctuation'},\n",
       " {'text': ' ', 'type': 'Token.Text', 'base_type': 'Text'},\n",
       " {'text': 'for', 'type': 'Token.Keyword', 'base_type': 'Keyword'},\n",
       " {'text': ' ', 'type': 'Token.Text', 'base_type': 'Text'},\n",
       " {'text': '_', 'type': 'Token.Name', 'base_type': 'Name'},\n",
       " {'text': ' ', 'type': 'Token.Text', 'base_type': 'Text'},\n",
       " {'text': 'in', 'type': 'Token.Operator.Word', 'base_type': 'Operator'},\n",
       " {'text': ' ', 'type': 'Token.Text', 'base_type': 'Text'},\n",
       " {'text': 'range', 'type': 'Token.Name.Builtin', 'base_type': 'Name'},\n",
       " {'text': '(', 'type': 'Token.Punctuation', 'base_type': 'Punctuation'},\n",
       " {'text': 'n', 'type': 'Token.Name', 'base_type': 'Name'},\n",
       " {'text': ')', 'type': 'Token.Punctuation', 'base_type': 'Punctuation'},\n",
       " {'text': ']', 'type': 'Token.Punctuation', 'base_type': 'Punctuation'},\n",
       " {'text': '\\n', 'type': 'Token.Text.Whitespace', 'base_type': 'Text'},\n",
       " {'text': '    ', 'type': 'Token.Text', 'base_type': 'Text'},\n",
       " {'text': 'index', 'type': 'Token.Name', 'base_type': 'Name'},\n",
       " {'text': ' ', 'type': 'Token.Text', 'base_type': 'Text'},\n",
       " {'text': '+', 'type': 'Token.Operator', 'base_type': 'Operator'},\n",
       " {'text': '=', 'type': 'Token.Operator', 'base_type': 'Operator'},\n",
       " {'text': ' ', 'type': 'Token.Text', 'base_type': 'Text'},\n",
       " {'text': '2', 'type': 'Token.Literal.Number.Integer', 'base_type': 'Literal'},\n",
       " {'text': ' ', 'type': 'Token.Text', 'base_type': 'Text'},\n",
       " {'text': '*', 'type': 'Token.Operator', 'base_type': 'Operator'},\n",
       " {'text': ' ', 'type': 'Token.Text', 'base_type': 'Text'},\n",
       " {'text': 'n', 'type': 'Token.Name', 'base_type': 'Name'},\n",
       " {'text': '\\n', 'type': 'Token.Text.Whitespace', 'base_type': 'Text'},\n",
       " {'text': '\\n', 'type': 'Token.Text.Whitespace', 'base_type': 'Text'},\n",
       " {'text': '    ', 'type': 'Token.Text', 'base_type': 'Text'},\n",
       " {'text': 'q', 'type': 'Token.Name', 'base_type': 'Name'},\n",
       " {'text': ' ', 'type': 'Token.Text', 'base_type': 'Text'},\n",
       " {'text': '=', 'type': 'Token.Operator', 'base_type': 'Operator'},\n",
       " {'text': ' ', 'type': 'Token.Text', 'base_type': 'Text'},\n",
       " {'text': 'int', 'type': 'Token.Name.Builtin', 'base_type': 'Name'},\n",
       " {'text': '(', 'type': 'Token.Punctuation', 'base_type': 'Punctuation'},\n",
       " {'text': 'data', 'type': 'Token.Name', 'base_type': 'Name'},\n",
       " {'text': '[', 'type': 'Token.Punctuation', 'base_type': 'Punctuation'},\n",
       " {'text': 'index', 'type': 'Token.Name', 'base_type': 'Name'},\n",
       " {'text': ']', 'type': 'Token.Punctuation', 'base_type': 'Punctuation'},\n",
       " {'text': ')', 'type': 'Token.Punctuation', 'base_type': 'Punctuation'},\n",
       " {'text': '\\n', 'type': 'Token.Text.Whitespace', 'base_type': 'Text'},\n",
       " {'text': '    ', 'type': 'Token.Text', 'base_type': 'Text'},\n",
       " {'text': 'index', 'type': 'Token.Name', 'base_type': 'Name'},\n",
       " {'text': ' ', 'type': 'Token.Text', 'base_type': 'Text'},\n",
       " {'text': '+', 'type': 'Token.Operator', 'base_type': 'Operator'},\n",
       " {'text': '=', 'type': 'Token.Operator', 'base_type': 'Operator'},\n",
       " {'text': ' ', 'type': 'Token.Text', 'base_type': 'Text'},\n",
       " {'text': '1', 'type': 'Token.Literal.Number.Integer', 'base_type': 'Literal'},\n",
       " {'text': '\\n', 'type': 'Token.Text.Whitespace', 'base_type': 'Text'},\n",
       " {'text': '    ', 'type': 'Token.Text', 'base_type': 'Text'},\n",
       " {'text': 'queries', 'type': 'Token.Name', 'base_type': 'Name'},\n",
       " {'text': ' ', 'type': 'Token.Text', 'base_type': 'Text'},\n",
       " {'text': '=', 'type': 'Token.Operator', 'base_type': 'Operator'},\n",
       " {'text': ' ', 'type': 'Token.Text', 'base_type': 'Text'},\n",
       " {'text': '[', 'type': 'Token.Punctuation', 'base_type': 'Punctuation'},\n",
       " {'text': '(', 'type': 'Token.Punctuation', 'base_type': 'Punctuation'},\n",
       " {'text': 'int', 'type': 'Token.Name.Builtin', 'base_type': 'Name'},\n",
       " {'text': '(', 'type': 'Token.Punctuation', 'base_type': 'Punctuation'},\n",
       " {'text': 'data', 'type': 'Token.Name', 'base_type': 'Name'},\n",
       " {'text': '[', 'type': 'Token.Punctuation', 'base_type': 'Punctuation'},\n",
       " {'text': 'index', 'type': 'Token.Name', 'base_type': 'Name'},\n",
       " {'text': ']', 'type': 'Token.Punctuation', 'base_type': 'Punctuation'},\n",
       " {'text': ')', 'type': 'Token.Punctuation', 'base_type': 'Punctuation'},\n",
       " {'text': ',', 'type': 'Token.Punctuation', 'base_type': 'Punctuation'},\n",
       " {'text': ' ', 'type': 'Token.Text', 'base_type': 'Text'},\n",
       " {'text': 'int', 'type': 'Token.Name.Builtin', 'base_type': 'Name'},\n",
       " {'text': '(', 'type': 'Token.Punctuation', 'base_type': 'Punctuation'},\n",
       " {'text': 'data', 'type': 'Token.Name', 'base_type': 'Name'},\n",
       " {'text': '[', 'type': 'Token.Punctuation', 'base_type': 'Punctuation'},\n",
       " {'text': 'index', 'type': 'Token.Name', 'base_type': 'Name'},\n",
       " {'text': ' ', 'type': 'Token.Text', 'base_type': 'Text'},\n",
       " {'text': '+', 'type': 'Token.Operator', 'base_type': 'Operator'},\n",
       " {'text': ' ', 'type': 'Token.Text', 'base_type': 'Text'},\n",
       " {'text': '1', 'type': 'Token.Literal.Number.Integer', 'base_type': 'Literal'},\n",
       " {'text': ']', 'type': 'Token.Punctuation', 'base_type': 'Punctuation'},\n",
       " {'text': ')', 'type': 'Token.Punctuation', 'base_type': 'Punctuation'},\n",
       " {'text': ',', 'type': 'Token.Punctuation', 'base_type': 'Punctuation'},\n",
       " {'text': ' ', 'type': 'Token.Text', 'base_type': 'Text'},\n",
       " {'text': 'int', 'type': 'Token.Name.Builtin', 'base_type': 'Name'},\n",
       " {'text': '(', 'type': 'Token.Punctuation', 'base_type': 'Punctuation'},\n",
       " {'text': 'data', 'type': 'Token.Name', 'base_type': 'Name'},\n",
       " {'text': '[', 'type': 'Token.Punctuation', 'base_type': 'Punctuation'},\n",
       " {'text': 'index', 'type': 'Token.Name', 'base_type': 'Name'},\n",
       " {'text': ' ', 'type': 'Token.Text', 'base_type': 'Text'},\n",
       " {'text': '+', 'type': 'Token.Operator', 'base_type': 'Operator'},\n",
       " {'text': ' ', 'type': 'Token.Text', 'base_type': 'Text'},\n",
       " {'text': '2', 'type': 'Token.Literal.Number.Integer', 'base_type': 'Literal'},\n",
       " {'text': ']', 'type': 'Token.Punctuation', 'base_type': 'Punctuation'},\n",
       " {'text': ')', 'type': 'Token.Punctuation', 'base_type': 'Punctuation'},\n",
       " {'text': ',', 'type': 'Token.Punctuation', 'base_type': 'Punctuation'},\n",
       " {'text': ' ', 'type': 'Token.Text', 'base_type': 'Text'},\n",
       " {'text': 'int', 'type': 'Token.Name.Builtin', 'base_type': 'Name'},\n",
       " {'text': '(', 'type': 'Token.Punctuation', 'base_type': 'Punctuation'},\n",
       " {'text': 'data', 'type': 'Token.Name', 'base_type': 'Name'},\n",
       " {'text': '[', 'type': 'Token.Punctuation', 'base_type': 'Punctuation'},\n",
       " {'text': 'index', 'type': 'Token.Name', 'base_type': 'Name'},\n",
       " {'text': ' ', 'type': 'Token.Text', 'base_type': 'Text'},\n",
       " {'text': '+', 'type': 'Token.Operator', 'base_type': 'Operator'},\n",
       " {'text': ' ', 'type': 'Token.Text', 'base_type': 'Text'},\n",
       " {'text': '3', 'type': 'Token.Literal.Number.Integer', 'base_type': 'Literal'},\n",
       " {'text': ']', 'type': 'Token.Punctuation', 'base_type': 'Punctuation'},\n",
       " {'text': ')', 'type': 'Token.Punctuation', 'base_type': 'Punctuation'},\n",
       " {'text': ')', 'type': 'Token.Punctuation', 'base_type': 'Punctuation'},\n",
       " {'text': ' ', 'type': 'Token.Text', 'base_type': 'Text'},\n",
       " {'text': 'for', 'type': 'Token.Keyword', 'base_type': 'Keyword'},\n",
       " {'text': ' ', 'type': 'Token.Text', 'base_type': 'Text'},\n",
       " {'text': '_', 'type': 'Token.Name', 'base_type': 'Name'},\n",
       " {'text': ' ', 'type': 'Token.Text', 'base_type': 'Text'},\n",
       " {'text': 'in', 'type': 'Token.Operator.Word', 'base_type': 'Operator'},\n",
       " {'text': ' ', 'type': 'Token.Text', 'base_type': 'Text'},\n",
       " {'text': 'range', 'type': 'Token.Name.Builtin', 'base_type': 'Name'},\n",
       " {'text': '(', 'type': 'Token.Punctuation', 'base_type': 'Punctuation'},\n",
       " {'text': 'q', 'type': 'Token.Name', 'base_type': 'Name'},\n",
       " {'text': ')', 'type': 'Token.Punctuation', 'base_type': 'Punctuation'},\n",
       " {'text': ']', 'type': 'Token.Punctuation', 'base_type': 'Punctuation'},\n",
       " {'text': '\\n', 'type': 'Token.Text.Whitespace', 'base_type': 'Text'},\n",
       " {'text': '    ', 'type': 'Token.Text', 'base_type': 'Text'},\n",
       " {'text': '\\n', 'type': 'Token.Text.Whitespace', 'base_type': 'Text'},\n",
       " {'text': '    ', 'type': 'Token.Text', 'base_type': 'Text'},\n",
       " {'text': 'range_search', 'type': 'Token.Name', 'base_type': 'Name'},\n",
       " {'text': '(', 'type': 'Token.Punctuation', 'base_type': 'Punctuation'},\n",
       " {'text': 'points', 'type': 'Token.Name', 'base_type': 'Name'},\n",
       " {'text': ',', 'type': 'Token.Punctuation', 'base_type': 'Punctuation'},\n",
       " {'text': ' ', 'type': 'Token.Text', 'base_type': 'Text'},\n",
       " {'text': 'queries', 'type': 'Token.Name', 'base_type': 'Name'},\n",
       " {'text': ')', 'type': 'Token.Punctuation', 'base_type': 'Punctuation'},\n",
       " {'text': '\\n', 'type': 'Token.Text.Whitespace', 'base_type': 'Text'},\n",
       " {'text': '\\n', 'type': 'Token.Text.Whitespace', 'base_type': 'Text'},\n",
       " {'text': 'if', 'type': 'Token.Keyword', 'base_type': 'Keyword'},\n",
       " {'text': ' ', 'type': 'Token.Text', 'base_type': 'Text'},\n",
       " {'text': '__name__',\n",
       "  'type': 'Token.Name.Variable.Magic',\n",
       "  'base_type': 'Name'},\n",
       " {'text': ' ', 'type': 'Token.Text', 'base_type': 'Text'},\n",
       " {'text': '==', 'type': 'Token.Operator', 'base_type': 'Operator'},\n",
       " {'text': ' ', 'type': 'Token.Text', 'base_type': 'Text'},\n",
       " {'text': '\"', 'type': 'Token.Literal.String.Double', 'base_type': 'Literal'},\n",
       " {'text': '__main__',\n",
       "  'type': 'Token.Literal.String.Double',\n",
       "  'base_type': 'Literal'},\n",
       " {'text': '\"', 'type': 'Token.Literal.String.Double', 'base_type': 'Literal'},\n",
       " {'text': ':', 'type': 'Token.Punctuation', 'base_type': 'Punctuation'},\n",
       " {'text': '\\n', 'type': 'Token.Text.Whitespace', 'base_type': 'Text'},\n",
       " {'text': '    ', 'type': 'Token.Text', 'base_type': 'Text'},\n",
       " {'text': 'main', 'type': 'Token.Name', 'base_type': 'Name'},\n",
       " {'text': '(', 'type': 'Token.Punctuation', 'base_type': 'Punctuation'},\n",
       " {'text': ')', 'type': 'Token.Punctuation', 'base_type': 'Punctuation'},\n",
       " {'text': '\\n', 'type': 'Token.Text.Whitespace', 'base_type': 'Text'}]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample[\"tokens\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72ac38d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fcf8a04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8c8477ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token Type                     | Value (repr)        \n",
      "-------------------------------------------------------\n",
      "Token.Keyword                  | 'class'             \n",
      "Token.Text.Whitespace          | ' '                 \n",
      "Token.Name.Class               | 'Solution'          \n",
      "Token.Punctuation              | ':'                 \n",
      "Token.Text.Whitespace          | '\\n'                \n",
      "Token.Text.Whitespace          | '\\n'                \n",
      "Token.Text                     | '\\t'                \n",
      "Token.Keyword                  | 'def'               \n",
      "Token.Text.Whitespace          | ' '                 \n",
      "Token.Name.Function            | 'maximumSum'        \n",
      "Token.Punctuation              | '('                 \n",
      "Token.Name.Builtin.Pseudo      | 'self'              \n",
      "Token.Punctuation              | ','                 \n",
      "Token.Text                     | ' '                 \n",
      "Token.Name                     | 'arr'               \n",
      "Token.Punctuation              | ':'                 \n",
      "Token.Text                     | ' '                 \n",
      "Token.Name                     | 'List'              \n",
      "Token.Punctuation              | '['                 \n",
      "Token.Name.Builtin             | 'int'               \n",
      "Token.Punctuation              | ']'                 \n",
      "Token.Punctuation              | ')'                 \n",
      "Token.Text                     | ' '                 \n",
      "Token.Operator                 | '-'                 \n",
      "Token.Operator                 | '>'                 \n",
      "Token.Text                     | ' '                 \n",
      "Token.Name.Builtin             | 'int'               \n",
      "Token.Punctuation              | ':'                 \n",
      "Token.Text.Whitespace          | '\\n'                \n",
      "Token.Text                     | '\\t\\t'              \n",
      "Token.Name                     | 'r'                 \n",
      "Token.Text                     | ' '                 \n",
      "Token.Operator                 | '='                 \n",
      "Token.Text                     | ' '                 \n",
      "Token.Name.Builtin             | 'max'               \n",
      "Token.Punctuation              | '('                 \n",
      "Token.Name                     | 'arr'               \n",
      "Token.Punctuation              | ')'                 \n",
      "Token.Text.Whitespace          | '\\n'                \n",
      "Token.Text                     | '\\t\\t'              \n",
      "Token.Keyword                  | 'if'                \n",
      "Token.Text                     | ' '                 \n",
      "Token.Name                     | 'r'                 \n",
      "Token.Text                     | ' '                 \n",
      "Token.Operator                 | '<'                 \n",
      "Token.Text                     | ' '                 \n",
      "Token.Literal.Number.Integer   | '0'                 \n",
      "Token.Punctuation              | ':'                 \n",
      "Token.Text.Whitespace          | '\\n'                \n",
      "Token.Text                     | '\\t\\t\\t'            \n",
      "Token.Keyword                  | 'return'            \n",
      "Token.Text                     | ' '                 \n",
      "Token.Name                     | 'r'                 \n",
      "Token.Text.Whitespace          | '\\n'                \n",
      "Token.Text                     | '\\t\\t'              \n",
      "Token.Name                     | 'l'                 \n",
      "Token.Text                     | ' '                 \n",
      "Token.Operator                 | '='                 \n",
      "Token.Text                     | ' '                 \n",
      "Token.Name.Builtin             | 'len'               \n",
      "Token.Punctuation              | '('                 \n",
      "Token.Name                     | 'arr'               \n",
      "Token.Punctuation              | ')'                 \n",
      "Token.Text.Whitespace          | '\\n'                \n",
      "Token.Text                     | '\\t\\t'              \n",
      "Token.Name                     | 'f'                 \n",
      "Token.Text                     | ' '                 \n",
      "Token.Operator                 | '='                 \n",
      "Token.Text                     | ' '                 \n",
      "Token.Punctuation              | '['                 \n",
      "Token.Literal.Number.Integer   | '0'                 \n",
      "Token.Punctuation              | ']'                 \n",
      "Token.Text                     | ' '                 \n",
      "Token.Operator                 | '*'                 \n",
      "Token.Text                     | ' '                 \n",
      "Token.Name                     | 'l'                 \n",
      "Token.Text.Whitespace          | '\\n'                \n",
      "Token.Text                     | '\\t\\t'              \n",
      "Token.Name                     | 'b'                 \n",
      "Token.Text                     | ' '                 \n",
      "Token.Operator                 | '='                 \n",
      "Token.Text                     | ' '                 \n",
      "Token.Punctuation              | '['                 \n",
      "Token.Literal.Number.Integer   | '0'                 \n",
      "Token.Punctuation              | ']'                 \n",
      "Token.Text                     | ' '                 \n",
      "Token.Operator                 | '*'                 \n",
      "Token.Text                     | ' '                 \n",
      "Token.Name                     | 'l'                 \n",
      "Token.Text.Whitespace          | '\\n'                \n",
      "Token.Text                     | '\\t\\t'              \n",
      "Token.Name                     | 'cur'               \n",
      "Token.Text                     | ' '                 \n",
      "Token.Operator                 | '='                 \n",
      "Token.Text                     | ' '                 \n",
      "Token.Literal.Number.Integer   | '0'                 \n",
      "Token.Text.Whitespace          | '\\n'                \n",
      "Token.Text                     | '\\t\\t'              \n",
      "Token.Keyword                  | 'for'               \n",
      "Token.Text                     | ' '                 \n",
      "Token.Name                     | 'i'                 \n",
      "Token.Text                     | ' '                 \n",
      "Token.Operator.Word            | 'in'                \n",
      "Token.Text                     | ' '                 \n",
      "Token.Name.Builtin             | 'range'             \n",
      "Token.Punctuation              | '('                 \n",
      "Token.Name                     | 'l'                 \n",
      "Token.Punctuation              | ')'                 \n",
      "Token.Punctuation              | ':'                 \n",
      "Token.Text.Whitespace          | '\\n'                \n",
      "Token.Text                     | '\\t\\t\\t'            \n",
      "Token.Name                     | 'f'                 \n",
      "Token.Punctuation              | '['                 \n",
      "Token.Name                     | 'i'                 \n",
      "Token.Punctuation              | ']'                 \n",
      "Token.Text                     | ' '                 \n",
      "Token.Operator                 | '='                 \n",
      "Token.Text                     | ' '                 \n",
      "Token.Name                     | 'cur'               \n",
      "Token.Text.Whitespace          | '\\n'                \n",
      "Token.Text                     | '\\t\\t\\t'            \n",
      "Token.Name                     | 'cur'               \n",
      "Token.Text                     | ' '                 \n",
      "Token.Operator                 | '+'                 \n",
      "Token.Operator                 | '='                 \n",
      "Token.Text                     | ' '                 \n",
      "Token.Name                     | 'arr'               \n",
      "Token.Punctuation              | '['                 \n",
      "Token.Name                     | 'i'                 \n",
      "Token.Punctuation              | ']'                 \n",
      "Token.Text.Whitespace          | '\\n'                \n",
      "Token.Text                     | '\\t\\t\\t'            \n",
      "Token.Name                     | 'cur'               \n",
      "Token.Text                     | ' '                 \n",
      "Token.Operator                 | '='                 \n",
      "Token.Text                     | ' '                 \n",
      "Token.Name.Builtin             | 'max'               \n",
      "Token.Punctuation              | '('                 \n",
      "Token.Name                     | 'cur'               \n",
      "Token.Punctuation              | ','                 \n",
      "Token.Text                     | ' '                 \n",
      "Token.Literal.Number.Integer   | '0'                 \n",
      "Token.Punctuation              | ')'                 \n",
      "Token.Text.Whitespace          | '\\n'                \n",
      "Token.Text                     | '\\t\\t'              \n",
      "Token.Name                     | 'cur'               \n",
      "Token.Text                     | ' '                 \n",
      "Token.Operator                 | '='                 \n",
      "Token.Text                     | ' '                 \n",
      "Token.Literal.Number.Integer   | '0'                 \n",
      "Token.Text.Whitespace          | '\\n'                \n",
      "Token.Text                     | '\\t\\t'              \n",
      "Token.Keyword                  | 'for'               \n",
      "Token.Text                     | ' '                 \n",
      "Token.Name                     | 'i'                 \n",
      "Token.Text                     | ' '                 \n",
      "Token.Operator.Word            | 'in'                \n",
      "Token.Text                     | ' '                 \n",
      "Token.Name.Builtin             | 'range'             \n",
      "Token.Punctuation              | '('                 \n",
      "Token.Name                     | 'l'                 \n",
      "Token.Text                     | ' '                 \n",
      "Token.Operator                 | '-'                 \n",
      "Token.Text                     | ' '                 \n",
      "Token.Literal.Number.Integer   | '1'                 \n",
      "Token.Punctuation              | ','                 \n",
      "Token.Text                     | ' '                 \n",
      "Token.Operator                 | '-'                 \n",
      "Token.Literal.Number.Integer   | '1'                 \n",
      "Token.Punctuation              | ','                 \n",
      "Token.Text                     | ' '                 \n",
      "Token.Operator                 | '-'                 \n",
      "Token.Literal.Number.Integer   | '1'                 \n",
      "Token.Punctuation              | ')'                 \n",
      "Token.Punctuation              | ':'                 \n",
      "Token.Text.Whitespace          | '\\n'                \n",
      "Token.Text                     | '\\t\\t\\t'            \n",
      "Token.Name                     | 'b'                 \n",
      "Token.Punctuation              | '['                 \n",
      "Token.Name                     | 'i'                 \n",
      "Token.Punctuation              | ']'                 \n",
      "Token.Text                     | ' '                 \n",
      "Token.Operator                 | '='                 \n",
      "Token.Text                     | ' '                 \n",
      "Token.Name                     | 'cur'               \n",
      "Token.Text.Whitespace          | '\\n'                \n",
      "Token.Text                     | '\\t\\t\\t'            \n",
      "Token.Name                     | 'cur'               \n",
      "Token.Text                     | ' '                 \n",
      "Token.Operator                 | '+'                 \n",
      "Token.Operator                 | '='                 \n",
      "Token.Text                     | ' '                 \n",
      "Token.Name                     | 'arr'               \n",
      "Token.Punctuation              | '['                 \n",
      "Token.Name                     | 'i'                 \n",
      "Token.Punctuation              | ']'                 \n",
      "Token.Text.Whitespace          | '\\n'                \n",
      "Token.Text                     | '\\t\\t\\t'            \n",
      "Token.Name                     | 'cur'               \n",
      "Token.Text                     | ' '                 \n",
      "Token.Operator                 | '='                 \n",
      "Token.Text                     | ' '                 \n",
      "Token.Name.Builtin             | 'max'               \n",
      "Token.Punctuation              | '('                 \n",
      "Token.Name                     | 'cur'               \n",
      "Token.Punctuation              | ','                 \n",
      "Token.Text                     | ' '                 \n",
      "Token.Literal.Number.Integer   | '0'                 \n",
      "Token.Punctuation              | ')'                 \n",
      "Token.Text.Whitespace          | '\\n'                \n",
      "Token.Text                     | '\\t\\t'              \n",
      "Token.Keyword                  | 'return'            \n",
      "Token.Text                     | ' '                 \n",
      "Token.Name.Builtin             | 'max'               \n",
      "Token.Punctuation              | '('                 \n",
      "Token.Punctuation              | '('                 \n",
      "Token.Name                     | 'f'                 \n",
      "Token.Punctuation              | '['                 \n",
      "Token.Name                     | 'i'                 \n",
      "Token.Punctuation              | ']'                 \n",
      "Token.Text                     | ' '                 \n",
      "Token.Operator                 | '+'                 \n",
      "Token.Text                     | ' '                 \n",
      "Token.Name                     | 'b'                 \n",
      "Token.Punctuation              | '['                 \n",
      "Token.Name                     | 'i'                 \n",
      "Token.Punctuation              | ']'                 \n",
      "Token.Text                     | ' '                 \n",
      "Token.Keyword                  | 'for'               \n",
      "Token.Text                     | ' '                 \n",
      "Token.Name                     | 'i'                 \n",
      "Token.Text                     | ' '                 \n",
      "Token.Operator.Word            | 'in'                \n",
      "Token.Text                     | ' '                 \n",
      "Token.Name.Builtin             | 'range'             \n",
      "Token.Punctuation              | '('                 \n",
      "Token.Name                     | 'l'                 \n",
      "Token.Punctuation              | ')'                 \n",
      "Token.Punctuation              | ')'                 \n",
      "Token.Punctuation              | ')'                 \n",
      "Token.Text.Whitespace          | '\\n'                \n"
     ]
    }
   ],
   "source": [
    "# Your input code string\n",
    "code_snippet = \"\"\"class Solution:\n",
    "\n",
    "\\tdef maximumSum(self, arr: List[int]) -> int:\n",
    "\\t\\tr = max(arr)\n",
    "\\t\\tif r < 0:\n",
    "\\t\\t\\treturn r\n",
    "\\t\\tl = len(arr)\n",
    "\\t\\tf = [0] * l\n",
    "\\t\\tb = [0] * l\n",
    "\\t\\tcur = 0\n",
    "\\t\\tfor i in range(l):\n",
    "\\t\\t\\tf[i] = cur\n",
    "\\t\\t\\tcur += arr[i]\n",
    "\\t\\t\\tcur = max(cur, 0)\n",
    "\\t\\tcur = 0\n",
    "\\t\\tfor i in range(l - 1, -1, -1):\n",
    "\\t\\t\\tb[i] = cur\n",
    "\\t\\t\\tcur += arr[i]\n",
    "\\t\\t\\tcur = max(cur, 0)\n",
    "\\t\\treturn max((f[i] + b[i] for i in range(l)))\n",
    "\"\"\"\n",
    "\n",
    "def tokenize_code(code):\n",
    "    # The lex() function returns a generator of (token_type, value) tuples\n",
    "    tokens = list(lex(code, PythonLexer()))\n",
    "    \n",
    "    print(f\"{'Token Type':<30} | {'Value (repr)':<20}\")\n",
    "    print(\"-\" * 55)\n",
    "    \n",
    "    for token_type, value in tokens:\n",
    "        # We use repr(value) to see hidden characters like \\t and \\n clearly\n",
    "        print(f\"{str(token_type):<30} | {repr(value):<20}\")\n",
    "\n",
    "tokenize_code(code_snippet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa3b54a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dbcf93d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "14baa0df",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"bigcode/starcoder\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "3624ce2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"Qwen/Qwen2.5-Coder-32B-Instruct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "540b87b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500000, 4) (100000, 4) (1000, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code</th>\n",
       "      <th>generator</th>\n",
       "      <th>label</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(a, b, c, d) = [int(x) for x in input().split(...</td>\n",
       "      <td>human</td>\n",
       "      <td>0</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>valid version for the language; all others can...</td>\n",
       "      <td>Qwen/Qwen2.5-Coder-1.5B</td>\n",
       "      <td>1</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                code                generator  \\\n",
       "0  (a, b, c, d) = [int(x) for x in input().split(...                    human   \n",
       "1  valid version for the language; all others can...  Qwen/Qwen2.5-Coder-1.5B   \n",
       "\n",
       "   label language  \n",
       "0      0   Python  \n",
       "1      1   Python  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "265c30fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class Solution:\n",
      "\n",
      "\tdef maximumSum(self, arr: List[int]) -> int:\n",
      "\t\tr = max(arr)\n",
      "\t\tif r < 0:\n",
      "\t\t\treturn r\n",
      "\t\tl = len(arr)\n",
      "\t\tf = [0] * l\n",
      "\t\tb = [0] * l\n",
      "\t\tcur = 0\n",
      "\t\tfor i in range(l):\n",
      "\t\t\tf[i] = cur\n",
      "\t\t\tcur += arr[i]\n",
      "\t\t\tcur = max(cur, 0)\n",
      "\t\tcur = 0\n",
      "\t\tfor i in range(l - 1, -1, -1):\n",
      "\t\t\tb[i] = cur\n",
      "\t\t\tcur += arr[i]\n",
      "\t\t\tcur = max(cur, 0)\n",
      "\t\treturn max((f[i] + b[i] for i in range(l)))\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sample = D_tr.sample().iloc[0]\n",
    "\n",
    "print(sample[\"code\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "95e5bd30",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import ngrams, word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "2d372b19",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: Pygments in /Users/rendvvv/miniconda3/envs/lingu/lib/python3.12/site-packages (2.19.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install Pygments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09685aec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'class Solution:\\n\\n\\tdef maximumSum(self, arr: List[int]) -> int:\\n\\t\\tr = max(arr)\\n\\t\\tif r < 0:\\n\\t\\t\\treturn r\\n\\t\\tl = len(arr)\\n\\t\\tf = [0] * l\\n\\t\\tb = [0] * l\\n\\t\\tcur = 0\\n\\t\\tfor i in range(l):\\n\\t\\t\\tf[i] = cur\\n\\t\\t\\tcur += arr[i]\\n\\t\\t\\tcur = max(cur, 0)\\n\\t\\tcur = 0\\n\\t\\tfor i in range(l - 1, -1, -1):\\n\\t\\t\\tb[i] = cur\\n\\t\\t\\tcur += arr[i]\\n\\t\\t\\tcur = max(cur, 0)\\n\\t\\treturn max((f[i] + b[i] for i in range(l)))\\n'"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample[\"code\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "808e2540",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bow_ngrams_from_doc(text, n=1):\n",
    "    tokens = [word for word in text.split(\" \")]\n",
    "    tokens = list(ngrams(tokens, n=n))\n",
    "    tokens = [\" \".join(token) for token in tokens]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "dc5eab61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['class',\n",
       " 'Solution:\\n\\n\\tdef',\n",
       " 'maximumSum(self,',\n",
       " 'arr:',\n",
       " 'List[int])',\n",
       " '->',\n",
       " 'int:\\n\\t\\tr',\n",
       " '=',\n",
       " 'max(arr)\\n\\t\\tif',\n",
       " 'r',\n",
       " '<',\n",
       " '0:\\n\\t\\t\\treturn',\n",
       " 'r\\n\\t\\tl',\n",
       " '=',\n",
       " 'len(arr)\\n\\t\\tf',\n",
       " '=',\n",
       " '[0]',\n",
       " '*',\n",
       " 'l\\n\\t\\tb',\n",
       " '=',\n",
       " '[0]',\n",
       " '*',\n",
       " 'l\\n\\t\\tcur',\n",
       " '=',\n",
       " '0\\n\\t\\tfor',\n",
       " 'i',\n",
       " 'in',\n",
       " 'range(l):\\n\\t\\t\\tf[i]',\n",
       " '=',\n",
       " 'cur\\n\\t\\t\\tcur',\n",
       " '+=',\n",
       " 'arr[i]\\n\\t\\t\\tcur',\n",
       " '=',\n",
       " 'max(cur,',\n",
       " '0)\\n\\t\\tcur',\n",
       " '=',\n",
       " '0\\n\\t\\tfor',\n",
       " 'i',\n",
       " 'in',\n",
       " 'range(l',\n",
       " '-',\n",
       " '1,',\n",
       " '-1,',\n",
       " '-1):\\n\\t\\t\\tb[i]',\n",
       " '=',\n",
       " 'cur\\n\\t\\t\\tcur',\n",
       " '+=',\n",
       " 'arr[i]\\n\\t\\t\\tcur',\n",
       " '=',\n",
       " 'max(cur,',\n",
       " '0)\\n\\t\\treturn',\n",
       " 'max((f[i]',\n",
       " '+',\n",
       " 'b[i]',\n",
       " 'for',\n",
       " 'i',\n",
       " 'in',\n",
       " 'range(l)))\\n']"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_bow_ngrams_from_doc(sample[\"code\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "57e3e40e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['def',\n",
       " 'Ġnth',\n",
       " 'Mag',\n",
       " 'ical',\n",
       " 'Number',\n",
       " '(N',\n",
       " ':',\n",
       " 'Ġint',\n",
       " ',',\n",
       " 'ĠA',\n",
       " ':',\n",
       " 'Ġint',\n",
       " ',',\n",
       " 'ĠB',\n",
       " ':',\n",
       " 'Ġint',\n",
       " ')',\n",
       " 'Ġ->',\n",
       " 'Ġint',\n",
       " ':Ċ',\n",
       " 'ĠĠĠ',\n",
       " 'ĠMOD',\n",
       " 'Ġ=',\n",
       " 'Ġ',\n",
       " '1',\n",
       " '0',\n",
       " '**',\n",
       " '9',\n",
       " 'Ġ+',\n",
       " 'Ġ',\n",
       " '7',\n",
       " 'Ċ',\n",
       " 'ĠĠĠ',\n",
       " 'Ġdef',\n",
       " 'Ġgcd',\n",
       " '(a',\n",
       " ',',\n",
       " 'Ġb',\n",
       " '):Ċ',\n",
       " 'ĠĠĠĠĠĠĠ',\n",
       " 'Ġwhile',\n",
       " 'Ġb',\n",
       " ':Ċ',\n",
       " 'ĠĠĠĠĠĠĠĠĠĠĠ',\n",
       " 'Ġa',\n",
       " ',',\n",
       " 'Ġb',\n",
       " 'Ġ=',\n",
       " 'Ġb',\n",
       " ',',\n",
       " 'Ġa',\n",
       " 'Ġ%',\n",
       " 'Ġb',\n",
       " 'Ċ',\n",
       " 'ĠĠĠĠĠĠĠ',\n",
       " 'Ġreturn',\n",
       " 'Ġa',\n",
       " 'ĊĊ',\n",
       " 'ĠĠĠ',\n",
       " 'Ġdef',\n",
       " 'Ġlcm',\n",
       " '(a',\n",
       " ',',\n",
       " 'Ġb',\n",
       " '):Ċ',\n",
       " 'ĠĠĠĠĠĠĠ',\n",
       " 'Ġreturn',\n",
       " 'Ġa',\n",
       " 'Ġ*',\n",
       " 'Ġb',\n",
       " 'Ġ//',\n",
       " 'Ġgcd',\n",
       " '(a',\n",
       " ',',\n",
       " 'Ġb',\n",
       " ')ĊĊ',\n",
       " 'ĠĠĠ',\n",
       " 'Ġleft',\n",
       " ',',\n",
       " 'Ġright',\n",
       " 'Ġ=',\n",
       " 'Ġmin',\n",
       " '(A',\n",
       " ',',\n",
       " 'ĠB',\n",
       " '),',\n",
       " 'ĠN',\n",
       " 'Ġ*',\n",
       " 'Ġmin',\n",
       " '(A',\n",
       " ',',\n",
       " 'ĠB',\n",
       " ')Ċ',\n",
       " 'ĠĠĠ',\n",
       " 'Ġwhile',\n",
       " 'Ġleft',\n",
       " 'Ġ<',\n",
       " 'Ġright',\n",
       " ':Ċ',\n",
       " 'ĠĠĠĠĠĠĠ',\n",
       " 'Ġmid',\n",
       " 'Ġ=',\n",
       " 'Ġ(',\n",
       " 'left',\n",
       " 'Ġ+',\n",
       " 'Ġright',\n",
       " ')',\n",
       " 'Ġ//',\n",
       " 'Ġ',\n",
       " '2',\n",
       " 'Ċ',\n",
       " 'ĠĠĠĠĠĠĠ',\n",
       " 'Ġif',\n",
       " 'Ġmid',\n",
       " 'Ġ//',\n",
       " 'ĠA',\n",
       " 'Ġ+',\n",
       " 'Ġmid',\n",
       " 'Ġ//',\n",
       " 'ĠB',\n",
       " 'Ġ-',\n",
       " 'Ġmid',\n",
       " 'Ġ//',\n",
       " 'Ġlcm',\n",
       " '(A',\n",
       " ',',\n",
       " 'ĠB',\n",
       " ')',\n",
       " 'Ġ<',\n",
       " 'ĠN',\n",
       " ':Ċ',\n",
       " 'ĠĠĠĠĠĠĠĠĠĠĠ',\n",
       " 'Ġleft',\n",
       " 'Ġ=',\n",
       " 'Ġmid',\n",
       " 'Ġ+',\n",
       " 'Ġ',\n",
       " '1',\n",
       " 'Ċ',\n",
       " 'ĠĠĠĠĠĠĠ',\n",
       " 'Ġelse',\n",
       " ':Ċ',\n",
       " 'ĠĠĠĠĠĠĠĠĠĠĠ',\n",
       " 'Ġright',\n",
       " 'Ġ=',\n",
       " 'Ġmid',\n",
       " 'Ċ',\n",
       " 'ĠĠĠ',\n",
       " 'Ġreturn',\n",
       " 'Ġleft',\n",
       " 'Ġ%',\n",
       " 'ĠMOD']"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.tokenize(sample[\"code\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a7550f58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meta-llama/Llama-3.3-70B-Instruct\n"
     ]
    }
   ],
   "source": [
    "print(sample[\"generator\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a3889efd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'Python': 91461, 'C++': 4679, 'Java': 3860})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(D_ev[\"language\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "58b40034",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'Python': 303,\n",
       "         'Java': 256,\n",
       "         'C#': 122,\n",
       "         'JavaScript': 85,\n",
       "         'C++': 75,\n",
       "         'Go': 60,\n",
       "         'C': 51,\n",
       "         'PHP': 48})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(D_te[\"language\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fbff66d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code</th>\n",
       "      <th>generator</th>\n",
       "      <th>label</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>public Vector To(Vector o)\\n        {\\n       ...</td>\n",
       "      <td>Human</td>\n",
       "      <td>0</td>\n",
       "      <td>C#</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>func (v *DefaultMessageSyntaxValidator) Valida...</td>\n",
       "      <td>Human</td>\n",
       "      <td>0</td>\n",
       "      <td>Go</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"\"\"Module managing testsuite capabilities\\n\\nC...</td>\n",
       "      <td>Human</td>\n",
       "      <td>0</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>void Anvil::Image::on_memory_backing_opaque_up...</td>\n",
       "      <td>Human</td>\n",
       "      <td>0</td>\n",
       "      <td>C++</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bool NOMAD::Priority_Eval_Point::dominates\\n( ...</td>\n",
       "      <td>Human</td>\n",
       "      <td>0</td>\n",
       "      <td>C++</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>/**-------------------------------------------...</td>\n",
       "      <td>Human</td>\n",
       "      <td>0</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>void AuxFunc(const dTensor1&amp; xpts, \\n\\t     dT...</td>\n",
       "      <td>Human</td>\n",
       "      <td>0</td>\n",
       "      <td>C++</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>def plot_confusion_matrix(\\n    context: MLCli...</td>\n",
       "      <td>Human</td>\n",
       "      <td>0</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>import sys\\nfrom collections import Counter\\n\\...</td>\n",
       "      <td>human</td>\n",
       "      <td>0</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>def assess_dimension(spectrum, rank, n_samples...</td>\n",
       "      <td>Human</td>\n",
       "      <td>0</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  code generator  label  \\\n",
       "0    public Vector To(Vector o)\\n        {\\n       ...     Human      0   \n",
       "1    func (v *DefaultMessageSyntaxValidator) Valida...     Human      0   \n",
       "2    \"\"\"Module managing testsuite capabilities\\n\\nC...     Human      0   \n",
       "3    void Anvil::Image::on_memory_backing_opaque_up...     Human      0   \n",
       "4    bool NOMAD::Priority_Eval_Point::dominates\\n( ...     Human      0   \n",
       "..                                                 ...       ...    ...   \n",
       "995  /**-------------------------------------------...     Human      0   \n",
       "996  void AuxFunc(const dTensor1& xpts, \\n\\t     dT...     Human      0   \n",
       "997  def plot_confusion_matrix(\\n    context: MLCli...     Human      0   \n",
       "998  import sys\\nfrom collections import Counter\\n\\...     human      0   \n",
       "999  def assess_dimension(spectrum, rank, n_samples...     Human      0   \n",
       "\n",
       "    language  \n",
       "0         C#  \n",
       "1         Go  \n",
       "2     Python  \n",
       "3        C++  \n",
       "4        C++  \n",
       "..       ...  \n",
       "995        C  \n",
       "996      C++  \n",
       "997   Python  \n",
       "998   Python  \n",
       "999   Python  \n",
       "\n",
       "[1000 rows x 4 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D_te"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "063a3ef3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e16214c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "830eacc0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "012ca49d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lingu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
